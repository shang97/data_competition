{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用gensim训练word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e4001f9910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 日志？?\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n",
    "\n",
    "# set seed\n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将训练集数据进行10折划分，保持类别的分布一致（代码拆开）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "n_example = 10000\n",
    "data_file = './train_set.csv.zip'\n",
    "train = pd.read_csv(data_file, sep='\\t')[:n_example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据直接全局变量\n",
    "train_texts = train['text'].tolist()\n",
    "train_labels = train['label'].tolist()\n",
    "n_total = len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data2index(fold_num):\n",
    "    \"\"\"读取df，将series转换为list进行处理\"\"\"\n",
    "        \n",
    "    # 1.所有数据打乱，通过打乱列表的索引来实现 / 通过sklearn的shuffle模块？\n",
    "    index = list(range(n_total))\n",
    "    np.random.shuffle(index)\n",
    "    all_texts = []\n",
    "    all_labels = []\n",
    "    for i in index:\n",
    "        all_texts.append(train_texts[i])\n",
    "        all_labels.append(train_labels[i])\n",
    "    \n",
    "    # 2.将所有数据按照类别进行划分，通过索引实现：字典检查某个键是否存在，不存在，就创建列表，存在则往列表里添加\n",
    "    label2id = {}\n",
    "    for i in range(n_total):\n",
    "        label = str(all_labels[i])\n",
    "        # 字典检查某个键是否存在？？ 不加.keys?\n",
    "        if label not in label2id:\n",
    "            label2id[label] = [i]\n",
    "        else:\n",
    "            label2id[label].append(i)\n",
    "    \n",
    "    # 3.\n",
    "    all_index = [[] for _ in range(fold_num)]\n",
    "    for label, data in label2id.items():\n",
    "        # print(label, len(data))\n",
    "        batch_size = int(len(data) / fold_num)\n",
    "        other = len(data) - batch_size * fold_num\n",
    "        \n",
    "        # 对每个类别都进行10折划分\n",
    "        for i in range(fold_num):\n",
    "            # if判断用于赋值\n",
    "            \n",
    "            # ？\n",
    "            cur_batch_size = batch_size + 1 if i < other else batch_size\n",
    "            # print(cur_batch_size)\n",
    "            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n",
    "            \n",
    "            # 总共包含10个列表，每个列表都包含所有类别的数据\n",
    "            all_index[i].extend(batch_data)\n",
    "            # 等价于 all_index = [], all_index.append(batch_data)\n",
    "            \n",
    "            \n",
    "    return all_texts, all_labels, all_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts, all_labels, all_index = all_data2index(n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2fold_data(all_texts, all_labels, all_index, fold_num):\n",
    "    \"\"\"这里的 texts、labels 是 fold_texts、fold_labels\"\"\"\n",
    "    \n",
    "    all_fold_data = []   \n",
    "    \n",
    "    # 4.根据每折的索引 划分出每折的数据，然后打乱\n",
    "    # 平均每折的数据量    \n",
    "    batch_size = int(n_total / fold_num)\n",
    "    other_texts = []\n",
    "    other_labels = []\n",
    "    other_num = 0\n",
    "    start = 0\n",
    "    for fold in range(fold_num):\n",
    "        # 每折的数据量\n",
    "        num = len(all_index[fold])\n",
    "        # 从所有数据索引中 索引出 每折数据 对应的text和label的索引\n",
    "        texts = [all_texts[i] for i in all_index[fold]]\n",
    "        labels = [all_labels[i] for i in all_index[fold]]\n",
    "        \n",
    "        # 如果每折的数据量 > 平均每折的数据量，对该折的数据进行缩减，只取到平均每折的数据量\n",
    "        if num > batch_size:\n",
    "            fold_texts = texts[:batch_size]\n",
    "            fold_labels = labels[:batch_size]           \n",
    "            other_texts.extend(texts[batch_size:])\n",
    "            other_labels.extend(labels[batch_size:])\n",
    "            other_num += num - batch_size\n",
    "            \n",
    "        # 如果每折的数据量 < 平均每折的数据量，则将上折剩余的数据补充到该折数据（列表的加法），直到取到平均每折的数据量\n",
    "        elif num < batch_size:\n",
    "            end = start + batch_size - num\n",
    "            # 如果上折剩余的数据量不足以补充该折数据呢，索引就会报错啊？？？？？？？？？？？？？？？\n",
    "            fold_texts = texts + other_texts[start: end]\n",
    "            fold_labels = labels + other_labels[start: end]\n",
    "            # 前面被补充过的数据不再使用\n",
    "            start = end\n",
    "        \n",
    "        # 如果每折的数据量 = 平均每折的数据量，该折的数据进行缩减，只取到平均\n",
    "        else:\n",
    "            fold_texts = texts\n",
    "            fold_labels = labels\n",
    "        \n",
    "        # 确保每折的数据量都等同于 平均每折的数据量\n",
    "        assert batch_size == len(fold_labels)\n",
    "    \n",
    "    # 那多出来的数据呢？？？？？？？？？？？？？？？？？？？？？\n",
    "    \n",
    "        # 对该折的数据进行打乱，通过列表的索引\n",
    "        fold_index = list(range(batch_size))\n",
    "        np.random.shuffle(fold_index)\n",
    "        shuffle_fold_texts = []\n",
    "        shuffle_fold_labels = []\n",
    "        for i in fold_index:\n",
    "            shuffle_fold_texts.append(fold_texts[i])\n",
    "            shuffle_fold_labels.append(fold_labels[i])\n",
    "        \n",
    "        # 将每折数据添加到 总划分数据里\n",
    "        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n",
    "        all_fold_data.append(data)\n",
    "    \n",
    "    # 记录输出 十折划分后 每折的数据量？？？\n",
    "    logging.info(\"Fold lens %s\", str([len(fold_data['label']) for fold_data in all_fold_data]))\n",
    "\n",
    "    return all_fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-24 09:51:09,683 INFO: Fold lens [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "all_fold_datas = index2fold_data(all_texts, all_labels, all_index, n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 \n",
      "\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n",
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_fold_datas), '\\n')\n",
    "\n",
    "all_folds = {}\n",
    "for i, fold_data in enumerate(all_fold_datas):\n",
    "    print(len(fold_data['label']), len(fold_data['text']))\n",
    "    all_folds['fold_' + str(i)] = pd.Series(fold_data['label']).value_counts() / len(fold_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每折的数据的数量和类别分布是否一致，**第一折的数据中没有类别13**  \n",
    "\n",
    "为什么分布结果和上个（没拆开，不是随机打乱数据？）一致？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_0</th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "      <th>fold_5</th>\n",
       "      <th>fold_6</th>\n",
       "      <th>fold_7</th>\n",
       "      <th>fold_8</th>\n",
       "      <th>fold_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold_0  fold_1  fold_2  fold_3  fold_4  fold_5  fold_6  fold_7  fold_8  \\\n",
       "0    0.189   0.189   0.189   0.189   0.189   0.188   0.188   0.188   0.188   \n",
       "1    0.187   0.187   0.187   0.187   0.187   0.187   0.186   0.186   0.186   \n",
       "2    0.157   0.156   0.156   0.156   0.156   0.156   0.156   0.156   0.156   \n",
       "3    0.108   0.108   0.108   0.108   0.108   0.108   0.108   0.108   0.107   \n",
       "4    0.079   0.079   0.079   0.079   0.079   0.079   0.079   0.079   0.078   \n",
       "5    0.062   0.062   0.062   0.062   0.062   0.062   0.062   0.062   0.062   \n",
       "6    0.051   0.051   0.051   0.051   0.051   0.050   0.050   0.050   0.050   \n",
       "7    0.043   0.043   0.043   0.043   0.043   0.043   0.042   0.042   0.042   \n",
       "8    0.042   0.042   0.042   0.042   0.042   0.041   0.041   0.041   0.041   \n",
       "9    0.031   0.031   0.031   0.031   0.031   0.031   0.031   0.031   0.031   \n",
       "10   0.025   0.025   0.024   0.024   0.024   0.024   0.024   0.024   0.024   \n",
       "11   0.017   0.017   0.017   0.017   0.016   0.016   0.016   0.016   0.016   \n",
       "12   0.009   0.009   0.009   0.009   0.009   0.009   0.009   0.009   0.008   \n",
       "13     NaN   0.001   0.002   0.002   0.003   0.006   0.008   0.008   0.011   \n",
       "\n",
       "    fold_9  \n",
       "0    0.188  \n",
       "1    0.186  \n",
       "2    0.156  \n",
       "3    0.107  \n",
       "4    0.078  \n",
       "5    0.061  \n",
       "6    0.050  \n",
       "7    0.042  \n",
       "8    0.041  \n",
       "9    0.031  \n",
       "10   0.024  \n",
       "11   0.016  \n",
       "12   0.008  \n",
       "13   0.012  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build train data for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-24 09:52:54,378 INFO: Total 9000 docs.\n"
     ]
    }
   ],
   "source": [
    "fold_id = 9\n",
    "\n",
    "train_texts = []\n",
    "for i in range(fold_id):\n",
    "    data = all_fold_datas[i]\n",
    "    train_texts.extend(data['text'])\n",
    "    \n",
    "logging.info('Total %d docs.' % len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x1e402a820f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: list(x.split()), train_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [['2109',\n",
       "   '932',\n",
       "   '3335',\n",
       "   '7261',\n",
       "   '3659',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '4464',\n",
       "   '1519',\n",
       "   '2716',\n",
       "   '1970',\n",
       "   '1363',\n",
       "   '5519',\n",
       "   '3266',\n",
       "   '6862',\n",
       "   '4933',\n",
       "   '1080',\n",
       "   '6122',\n",
       "   '6050',\n",
       "   '299',\n",
       "   '2786',\n",
       "   '7495',\n",
       "   '2435',\n",
       "   '4568',\n",
       "   '5915',\n",
       "   '134',\n",
       "   '2465',\n",
       "   '4464',\n",
       "   '4464',\n",
       "   '2073',\n",
       "   '3659',\n",
       "   '6065',\n",
       "   '4853',\n",
       "   '2087',\n",
       "   '6286',\n",
       "   '3750',\n",
       "   '932',\n",
       "   '2848',\n",
       "   '2444',\n",
       "   '3155',\n",
       "   '3772',\n",
       "   '3335',\n",
       "   '7261',\n",
       "   '3659',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '4464',\n",
       "   '1519',\n",
       "   '2716',\n",
       "   '1970',\n",
       "   '1363',\n",
       "   '5519',\n",
       "   '3266',\n",
       "   '6862',\n",
       "   '4933',\n",
       "   '2490',\n",
       "   '1080',\n",
       "   '6122',\n",
       "   '6050',\n",
       "   '299',\n",
       "   '2786',\n",
       "   '4648',\n",
       "   '6122',\n",
       "   '1906',\n",
       "   '7160',\n",
       "   '4480',\n",
       "   '299',\n",
       "   '6630',\n",
       "   '3500',\n",
       "   '3523',\n",
       "   '6093',\n",
       "   '5330',\n",
       "   '299',\n",
       "   '2786',\n",
       "   '4499',\n",
       "   '7010',\n",
       "   '900',\n",
       "   '2490',\n",
       "   '2716',\n",
       "   '1970',\n",
       "   '3659',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '4464',\n",
       "   '1519',\n",
       "   '1363',\n",
       "   '5519',\n",
       "   '3266',\n",
       "   '6862',\n",
       "   '4933',\n",
       "   '3335',\n",
       "   '3272',\n",
       "   '5057',\n",
       "   '7377',\n",
       "   '5410',\n",
       "   '648',\n",
       "   '6065',\n",
       "   '6250',\n",
       "   '3370',\n",
       "   '7186',\n",
       "   '299',\n",
       "   '6656',\n",
       "   '6810',\n",
       "   '6065',\n",
       "   '6250',\n",
       "   '2799',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '2109',\n",
       "   '932',\n",
       "   '1702',\n",
       "   '3300',\n",
       "   '4648',\n",
       "   '4464',\n",
       "   '3370',\n",
       "   '2073',\n",
       "   '4216',\n",
       "   '6835',\n",
       "   '5330',\n",
       "   '1363',\n",
       "   '5519',\n",
       "   '3266',\n",
       "   '6862',\n",
       "   '4933',\n",
       "   '5057',\n",
       "   '3700',\n",
       "   '2073',\n",
       "   '4216',\n",
       "   '648',\n",
       "   '3659',\n",
       "   '6250',\n",
       "   '3659',\n",
       "   '7186',\n",
       "   '2786',\n",
       "   '6810',\n",
       "   '3659',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '7186',\n",
       "   '4648',\n",
       "   '1215',\n",
       "   '5510',\n",
       "   '1363',\n",
       "   '5519',\n",
       "   '3266',\n",
       "   '6862',\n",
       "   '4933',\n",
       "   '1854',\n",
       "   '1735',\n",
       "   '619',\n",
       "   '3659',\n",
       "   '6250',\n",
       "   '4646',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '2109',\n",
       "   '932',\n",
       "   '4333',\n",
       "   '4648',\n",
       "   '6535',\n",
       "   '5598',\n",
       "   '2076',\n",
       "   '4958',\n",
       "   '4298',\n",
       "   '1363',\n",
       "   '5519',\n",
       "   '3266',\n",
       "   '6862',\n",
       "   '4648',\n",
       "   '3686',\n",
       "   '3374',\n",
       "   '6357',\n",
       "   '2614',\n",
       "   '3317',\n",
       "   '45',\n",
       "   '5948',\n",
       "   '3068',\n",
       "   '1459',\n",
       "   '2539',\n",
       "   '299',\n",
       "   '5122',\n",
       "   '2490',\n",
       "   '350',\n",
       "   '6017',\n",
       "   '512',\n",
       "   '2109',\n",
       "   '648',\n",
       "   '6012',\n",
       "   '6637',\n",
       "   '7006',\n",
       "   '6407',\n",
       "   '4648',\n",
       "   '3618',\n",
       "   '5998',\n",
       "   '2489',\n",
       "   '3220',\n",
       "   '1919',\n",
       "   '4939',\n",
       "   '6729',\n",
       "   '6050',\n",
       "   '1080',\n",
       "   '4958',\n",
       "   '2087',\n",
       "   '730',\n",
       "   '6045',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '6832',\n",
       "   '5011',\n",
       "   '648',\n",
       "   '4648',\n",
       "   '4811',\n",
       "   '6122',\n",
       "   '1906',\n",
       "   '648',\n",
       "   '1550',\n",
       "   '5977',\n",
       "   '2112',\n",
       "   '900'],\n",
       "  ['2693',\n",
       "   '2210',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '1699',\n",
       "   '5602',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '2106',\n",
       "   '2465',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '1699',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '5602',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '2693',\n",
       "   '1363',\n",
       "   '4412',\n",
       "   '2210',\n",
       "   '5491',\n",
       "   '4646',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '6065',\n",
       "   '3659',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '6293',\n",
       "   '1934',\n",
       "   '7055',\n",
       "   '3370',\n",
       "   '6065',\n",
       "   '6065',\n",
       "   '3659',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '1934',\n",
       "   '4315',\n",
       "   '2662',\n",
       "   '7044',\n",
       "   '4853',\n",
       "   '584',\n",
       "   '1920',\n",
       "   '151',\n",
       "   '4211',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '5858',\n",
       "   '2695',\n",
       "   '1767',\n",
       "   '4819',\n",
       "   '1722',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '2400',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '1699',\n",
       "   '1271',\n",
       "   '5036',\n",
       "   '5602',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '3370',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '340',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '648',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '5915',\n",
       "   '5860',\n",
       "   '4933',\n",
       "   '6656',\n",
       "   '6609',\n",
       "   '5977',\n",
       "   '2541',\n",
       "   '3166',\n",
       "   '3750',\n",
       "   '3695',\n",
       "   '1906',\n",
       "   '1699',\n",
       "   '1271',\n",
       "   '5036',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '5602',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '900',\n",
       "   '7329',\n",
       "   '5948',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '299',\n",
       "   '5264',\n",
       "   '5788',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '648',\n",
       "   '7467',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '4646',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '3700',\n",
       "   '2106',\n",
       "   '7261',\n",
       "   '663',\n",
       "   '3750',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '606',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '7371',\n",
       "   '6641',\n",
       "   '1401',\n",
       "   '3659',\n",
       "   '3700',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '2799',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '25',\n",
       "   '5948',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '299',\n",
       "   '5264',\n",
       "   '5788',\n",
       "   '648',\n",
       "   '7467',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '3700',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '7261',\n",
       "   '663',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '606',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '7371',\n",
       "   '6641',\n",
       "   '6065',\n",
       "   '4149',\n",
       "   '6250',\n",
       "   '3659',\n",
       "   '5602',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '7377',\n",
       "   '5410',\n",
       "   '151',\n",
       "   '4211',\n",
       "   '3750',\n",
       "   '5330',\n",
       "   '5677',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '7366',\n",
       "   '1271',\n",
       "   '4464',\n",
       "   '3370',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '2685',\n",
       "   '4464',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '5036',\n",
       "   '648',\n",
       "   '4269',\n",
       "   '2769',\n",
       "   '3634',\n",
       "   '5589',\n",
       "   '5510',\n",
       "   '5036',\n",
       "   '2549',\n",
       "   '3137',\n",
       "   '2685',\n",
       "   '900',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '340',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4269',\n",
       "   '2769',\n",
       "   '2541',\n",
       "   '3166',\n",
       "   '900',\n",
       "   '25',\n",
       "   '7377',\n",
       "   '5677',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '4969',\n",
       "   '3695',\n",
       "   '1906',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '3750',\n",
       "   '5948',\n",
       "   '6759',\n",
       "   '2210',\n",
       "   '3659',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '3370',\n",
       "   '1519',\n",
       "   '3659',\n",
       "   '2073',\n",
       "   '3659',\n",
       "   '6065',\n",
       "   '4853',\n",
       "   '1215',\n",
       "   '5036',\n",
       "   '5330',\n",
       "   '5602',\n",
       "   '2799',\n",
       "   '3700',\n",
       "   '6250',\n",
       "   '3700',\n",
       "   '5602',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '1699',\n",
       "   '6835',\n",
       "   '5011',\n",
       "   '3019',\n",
       "   '663',\n",
       "   '3750',\n",
       "   '736',\n",
       "   '7261',\n",
       "   '1375',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '4149',\n",
       "   '6065',\n",
       "   '6250',\n",
       "   '5602',\n",
       "   '3700',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '2400',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '1375',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '6065',\n",
       "   '3700',\n",
       "   '6250',\n",
       "   '2799',\n",
       "   '3700',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '1375',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '6065',\n",
       "   '5602',\n",
       "   '6250',\n",
       "   '4646',\n",
       "   '3370',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '3335',\n",
       "   '7261',\n",
       "   '5330',\n",
       "   '5677',\n",
       "   '6319',\n",
       "   '2539',\n",
       "   '1215',\n",
       "   '4986',\n",
       "   '1699',\n",
       "   '6065',\n",
       "   '6065',\n",
       "   '3370',\n",
       "   '6250',\n",
       "   '4149',\n",
       "   '4464',\n",
       "   '4230',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '2400',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '1375',\n",
       "   '6319',\n",
       "   '2539',\n",
       "   '4464',\n",
       "   '4149',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '3370',\n",
       "   '6065',\n",
       "   '4230',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '3335',\n",
       "   '7261',\n",
       "   '1375',\n",
       "   '6319',\n",
       "   '2539',\n",
       "   '4464',\n",
       "   '1324',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '4646',\n",
       "   '2799',\n",
       "   '4230',\n",
       "   '2106',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '1702',\n",
       "   '3300',\n",
       "   '3750',\n",
       "   '5330',\n",
       "   '5677',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '3151',\n",
       "   '1844',\n",
       "   '2539',\n",
       "   '5296',\n",
       "   '7399',\n",
       "   '5600',\n",
       "   '6535',\n",
       "   '2541',\n",
       "   '910',\n",
       "   '2252',\n",
       "   '2210',\n",
       "   '730',\n",
       "   '5430',\n",
       "   '5977',\n",
       "   '3750',\n",
       "   '2490',\n",
       "   '5589',\n",
       "   '2986',\n",
       "   '5430',\n",
       "   '619',\n",
       "   '6163',\n",
       "   '3247',\n",
       "   '5330',\n",
       "   '2210',\n",
       "   '2539',\n",
       "   '5330',\n",
       "   '5296',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '5264',\n",
       "   '5788',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '7467',\n",
       "   '619',\n",
       "   '4646',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '3700',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '6920',\n",
       "   '3370',\n",
       "   '6250',\n",
       "   '5602',\n",
       "   '4149',\n",
       "   '7186',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '7467',\n",
       "   '619',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '3700',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '6920',\n",
       "   '3370',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '4646',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '6104',\n",
       "   '3203',\n",
       "   '1080',\n",
       "   '4958',\n",
       "   '2708',\n",
       "   '2693',\n",
       "   '1363',\n",
       "   '4412',\n",
       "   '2210',\n",
       "   '6940',\n",
       "   '886',\n",
       "   '5109',\n",
       "   '885',\n",
       "   '2693',\n",
       "   '1363',\n",
       "   '4412',\n",
       "   '2210',\n",
       "   '5491',\n",
       "   '4646',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '6065',\n",
       "   '3659',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '6293',\n",
       "   '1934',\n",
       "   '7055',\n",
       "   '3370',\n",
       "   '6065',\n",
       "   '6065',\n",
       "   '3659',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '1934',\n",
       "   '4315',\n",
       "   '2662',\n",
       "   '7044',\n",
       "   '4853',\n",
       "   '584',\n",
       "   '1920',\n",
       "   '151',\n",
       "   '4211',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '5858',\n",
       "   '2695',\n",
       "   '1767',\n",
       "   '4819',\n",
       "   '1722',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '2400',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '1699',\n",
       "   '1271',\n",
       "   '5036',\n",
       "   '5602',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '3370',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '340',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '648',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '5702',\n",
       "   '5915',\n",
       "   '5860',\n",
       "   '4933',\n",
       "   '6656',\n",
       "   '6609',\n",
       "   '5977',\n",
       "   '2541',\n",
       "   '3166',\n",
       "   '3750',\n",
       "   '3695',\n",
       "   '1906',\n",
       "   '1699',\n",
       "   '1271',\n",
       "   '5036',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '5602',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '900',\n",
       "   '7329',\n",
       "   '5948',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '299',\n",
       "   '5264',\n",
       "   '5788',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '648',\n",
       "   '7467',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '4646',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '3700',\n",
       "   '2106',\n",
       "   '7261',\n",
       "   '663',\n",
       "   '3750',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '606',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '7371',\n",
       "   '6641',\n",
       "   '1401',\n",
       "   '3659',\n",
       "   '3700',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '2799',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '25',\n",
       "   '5948',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '299',\n",
       "   '5264',\n",
       "   '5788',\n",
       "   '648',\n",
       "   '7467',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '3700',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '7261',\n",
       "   '663',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '6637',\n",
       "   '606',\n",
       "   '6357',\n",
       "   '6637',\n",
       "   '7371',\n",
       "   '6641',\n",
       "   '6065',\n",
       "   '4149',\n",
       "   '6250',\n",
       "   '3659',\n",
       "   '5602',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '7377',\n",
       "   '5410',\n",
       "   '151',\n",
       "   '4211',\n",
       "   '3750',\n",
       "   '5330',\n",
       "   '5677',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '7366',\n",
       "   '1271',\n",
       "   '4464',\n",
       "   '3370',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '2685',\n",
       "   '4464',\n",
       "   '6250',\n",
       "   '1324',\n",
       "   '5036',\n",
       "   '648',\n",
       "   '4269',\n",
       "   '2769',\n",
       "   '3634',\n",
       "   '5589',\n",
       "   '5510',\n",
       "   '5036',\n",
       "   '2549',\n",
       "   '3137',\n",
       "   '2685',\n",
       "   '900',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '340',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4269',\n",
       "   '2769',\n",
       "   '2541',\n",
       "   '3166',\n",
       "   '900',\n",
       "   '25',\n",
       "   '7377',\n",
       "   '5677',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '4969',\n",
       "   '3695',\n",
       "   '1906',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '3750',\n",
       "   '5948',\n",
       "   '6759',\n",
       "   '2210',\n",
       "   '3659',\n",
       "   '3370',\n",
       "   '4464',\n",
       "   '3370',\n",
       "   '1519',\n",
       "   '3659',\n",
       "   '2073',\n",
       "   '3659',\n",
       "   '6065',\n",
       "   '4853',\n",
       "   '1215',\n",
       "   '5036',\n",
       "   '5330',\n",
       "   '5602',\n",
       "   '2799',\n",
       "   '3700',\n",
       "   '6250',\n",
       "   '3700',\n",
       "   '5602',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '1699',\n",
       "   '6835',\n",
       "   '5011',\n",
       "   '3019',\n",
       "   '663',\n",
       "   '3750',\n",
       "   '736',\n",
       "   '7261',\n",
       "   '1375',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '4149',\n",
       "   '6065',\n",
       "   '6250',\n",
       "   '5602',\n",
       "   '3700',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '2400',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '1375',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '6065',\n",
       "   '3700',\n",
       "   '6250',\n",
       "   '2799',\n",
       "   '3700',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '1375',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '4216',\n",
       "   '5011',\n",
       "   '6980',\n",
       "   '6065',\n",
       "   '5602',\n",
       "   '6250',\n",
       "   '4646',\n",
       "   '3370',\n",
       "   '4230',\n",
       "   '5036',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '3335',\n",
       "   '7261',\n",
       "   '5330',\n",
       "   '5677',\n",
       "   '6319',\n",
       "   '2539',\n",
       "   '1215',\n",
       "   '4986',\n",
       "   '1699',\n",
       "   '6065',\n",
       "   '6065',\n",
       "   '3370',\n",
       "   '6250',\n",
       "   '4149',\n",
       "   '4464',\n",
       "   '4230',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '4822',\n",
       "   '2400',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '1375',\n",
       "   '6319',\n",
       "   '2539',\n",
       "   '4464',\n",
       "   '4149',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '3370',\n",
       "   '6065',\n",
       "   '4230',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '3335',\n",
       "   '7261',\n",
       "   '1375',\n",
       "   '6319',\n",
       "   '2539',\n",
       "   '4464',\n",
       "   '1324',\n",
       "   '1324',\n",
       "   '6250',\n",
       "   '4646',\n",
       "   '2799',\n",
       "   '4230',\n",
       "   '2106',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '1702',\n",
       "   '3300',\n",
       "   '3750',\n",
       "   '5330',\n",
       "   '5677',\n",
       "   '3137',\n",
       "   '5036',\n",
       "   '3151',\n",
       "   '1844',\n",
       "   '2539',\n",
       "   '5296',\n",
       "   '7399',\n",
       "   '5600',\n",
       "   '6535',\n",
       "   '2541',\n",
       "   '910',\n",
       "   '2252',\n",
       "   '2210',\n",
       "   '730',\n",
       "   '5430',\n",
       "   '5977',\n",
       "   '3750',\n",
       "   '2490',\n",
       "   '5589',\n",
       "   '2986',\n",
       "   '5430',\n",
       "   '619',\n",
       "   '6163',\n",
       "   '3247',\n",
       "   '5330',\n",
       "   '2210',\n",
       "   '2539',\n",
       "   '5330',\n",
       "   '5296',\n",
       "   '900',\n",
       "   '2693',\n",
       "   '2210',\n",
       "   '5264',\n",
       "   '5788',\n",
       "   '3661',\n",
       "   '5036',\n",
       "   '7467',\n",
       "   '619',\n",
       "   '4646',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '3700',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '6920',\n",
       "   '3370',\n",
       "   '6250',\n",
       "   '5602',\n",
       "   '4149',\n",
       "   '7186',\n",
       "   '3750',\n",
       "   '1934',\n",
       "   '5036',\n",
       "   '7467',\n",
       "   '619',\n",
       "   '2799',\n",
       "   '6250',\n",
       "   '4464',\n",
       "   '3700',\n",
       "   '1970',\n",
       "   '2106',\n",
       "   '3750',\n",
       "   '6920',\n",
       "   '3370',\n",
       "   '6250',\n",
       "   '6065',\n",
       "   '4646',\n",
       "   '7186',\n",
       "   '900',\n",
       "   '6104',\n",
       "   '3203',\n",
       "   '1080',\n",
       "   '4958',\n",
       "   '2708',\n",
       "   '2693',\n",
       "   '1363',\n",
       "   '4412',\n",
       "   '2210',\n",
       "   '6940',\n",
       "   '886',\n",
       "   '5109',\n",
       "   '885']])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list可视化\n",
    "a = list(map(lambda x: list(x.split()), train_texts[:2]))\n",
    "len(a), a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-24 10:05:37,016 INFO: Start training...\n",
      "2020-07-24 10:05:39,427 INFO: collecting all words and their counts\n",
      "2020-07-24 10:05:39,427 INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-24 10:05:40,449 INFO: collected 5295 word types from a corpus of 8191447 raw words and 9000 sentences\n",
      "2020-07-24 10:05:40,449 INFO: Loading a fresh vocabulary\n",
      "2020-07-24 10:05:40,521 INFO: effective_min_count=5 retains 4335 unique words (81% of original 5295, drops 960)\n",
      "2020-07-24 10:05:40,522 INFO: effective_min_count=5 leaves 8189498 word corpus (99% of original 8191447, drops 1949)\n",
      "2020-07-24 10:05:40,533 INFO: deleting the raw counts dictionary of 5295 items\n",
      "2020-07-24 10:05:40,534 INFO: sample=0.001 downsamples 61 most-common words\n",
      "2020-07-24 10:05:40,534 INFO: downsampling leaves estimated 7070438 word corpus (86.3% of prior 8189498)\n",
      "2020-07-24 10:05:40,544 INFO: estimated required memory for 4335 words and 100 dimensions: 5635500 bytes\n",
      "2020-07-24 10:05:40,545 INFO: resetting layer weights\n",
      "2020-07-24 10:05:41,273 INFO: training model with 3 workers on 4335 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-24 10:05:42,284 INFO: EPOCH 1 - PROGRESS: at 29.62% examples, 2072786 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:43,284 INFO: EPOCH 1 - PROGRESS: at 59.18% examples, 2058873 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:44,284 INFO: EPOCH 1 - PROGRESS: at 87.58% examples, 2054150 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:44,689 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-24 10:05:44,692 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-24 10:05:44,696 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-24 10:05:44,697 INFO: EPOCH - 1 : training on 8191447 raw words (7021402 effective words) took 3.4s, 2052420 effective words/s\n",
      "2020-07-24 10:05:45,701 INFO: EPOCH 2 - PROGRESS: at 28.44% examples, 1998959 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:46,709 INFO: EPOCH 2 - PROGRESS: at 57.39% examples, 1994624 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:47,719 INFO: EPOCH 2 - PROGRESS: at 85.29% examples, 1987602 words/s, in_qsize 6, out_qsize 1\n",
      "2020-07-24 10:05:48,227 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-24 10:05:48,228 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-24 10:05:48,240 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-24 10:05:48,241 INFO: EPOCH - 2 : training on 8191447 raw words (7021739 effective words) took 3.5s, 1982513 effective words/s\n",
      "2020-07-24 10:05:49,245 INFO: EPOCH 3 - PROGRESS: at 29.73% examples, 2093475 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:50,254 INFO: EPOCH 3 - PROGRESS: at 59.40% examples, 2068520 words/s, in_qsize 5, out_qsize 1\n",
      "2020-07-24 10:05:51,258 INFO: EPOCH 3 - PROGRESS: at 89.28% examples, 2085019 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:51,604 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-24 10:05:51,607 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-24 10:05:51,610 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-24 10:05:51,612 INFO: EPOCH - 3 : training on 8191447 raw words (7020305 effective words) took 3.4s, 2084153 effective words/s\n",
      "2020-07-24 10:05:52,617 INFO: EPOCH 4 - PROGRESS: at 27.62% examples, 1944528 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:53,623 INFO: EPOCH 4 - PROGRESS: at 56.30% examples, 1961140 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-24 10:05:54,632 INFO: EPOCH 4 - PROGRESS: at 85.17% examples, 1988049 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-24 10:05:55,153 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-24 10:05:55,155 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-24 10:05:55,163 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-24 10:05:55,164 INFO: EPOCH - 4 : training on 8191447 raw words (7021406 effective words) took 3.5s, 1979214 effective words/s\n",
      "2020-07-24 10:05:56,170 INFO: EPOCH 5 - PROGRESS: at 28.97% examples, 2034764 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-24 10:05:57,171 INFO: EPOCH 5 - PROGRESS: at 59.11% examples, 2060600 words/s, in_qsize 5, out_qsize 0\n",
      "2020-07-24 10:05:58,173 INFO: EPOCH 5 - PROGRESS: at 87.39% examples, 2050848 words/s, in_qsize 6, out_qsize 0\n",
      "2020-07-24 10:05:58,588 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-24 10:05:58,591 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-24 10:05:58,594 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-24 10:05:58,596 INFO: EPOCH - 5 : training on 8191447 raw words (7022369 effective words) took 3.4s, 2047813 effective words/s\n",
      "2020-07-24 10:05:58,597 INFO: training on a 40957235 raw words (35107221 effective words) took 17.3s, 2026645 effective words/s\n",
      "2020-07-24 10:05:58,598 INFO: precomputing L2-norms of word weight vectors\n",
      "2020-07-24 10:05:58,600 INFO: saving Word2Vec object under ./word2vec.bin, separately None\n",
      "2020-07-24 10:05:58,601 INFO: not storing attribute vectors_norm\n",
      "2020-07-24 10:05:58,603 INFO: not storing attribute cum_table\n",
      "2020-07-24 10:05:58,639 INFO: saved ./word2vec.bin\n"
     ]
    }
   ],
   "source": [
    "logging.info('Start training...')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "num_features = 100     # Word vector dimensionality\n",
    "num_workers = 3      # Number of threads to run in parallel\n",
    "\n",
    "# 对train_texts中的每个元素都运用该自定义函数，list使得map对象 可被展示\n",
    "train_texts = list(map(lambda x: list(x.split()), train_texts))\n",
    "model = Word2Vec(train_texts, workers=num_workers, size=num_features)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model\n",
    "model.save(\"./word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载word2vec模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-24 10:07:52,255 INFO: loading Word2Vec object from ./word2vec.bin\n",
      "2020-07-24 10:07:52,299 INFO: loading wv recursively from ./word2vec.bin.wv.* with mmap=None\n",
      "2020-07-24 10:07:52,299 INFO: setting ignored attribute vectors_norm to None\n",
      "2020-07-24 10:07:52,300 INFO: loading vocabulary recursively from ./word2vec.bin.vocabulary.* with mmap=None\n",
      "2020-07-24 10:07:52,300 INFO: loading trainables recursively from ./word2vec.bin.trainables.* with mmap=None\n",
      "2020-07-24 10:07:52,301 INFO: setting ignored attribute cum_table to None\n",
      "2020-07-24 10:07:52,301 INFO: loaded ./word2vec.bin\n",
      "2020-07-24 10:07:52,312 INFO: storing 4335x100 projection weights into ./word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = Word2Vec.load(\"./word2vec.bin\")\n",
    "\n",
    "# convert format\n",
    "model.wv.save_word2vec_format('./word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
