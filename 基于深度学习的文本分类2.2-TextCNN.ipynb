{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextCNN利用CNN（卷积神经网络）进行**文本特征抽取**，不同大小的卷积核分别抽取n-gram特征，卷积计算出的**特征图**经过MaxPooling保留最大的特征值，然后**拼接成一个向量作为文本的表示**。\n",
    "\n",
    "这里我们基于TextCNN原始论文的设定，分别采用了100个大小为2,3,4的卷积核，最后得到的文本向量大小为100*3=300维\n",
    "\n",
    "### 一、十折验证数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 11:46:49,573 INFO: Use cuda: True, gpu id: 0.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n",
    "\n",
    "# set seed\n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set cuda\n",
    "gpu = 0\n",
    "# 右边是个bool判断，返回True或者False\n",
    "use_cuda = gpu >= 0 and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(gpu)\n",
    "    device = torch.device(\"cuda\", gpu)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "logging.info(\"Use cuda: %s, gpu id: %d.\", use_cuda, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统一的十折交叉验证（训练集）数据的加载方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "n_example = 2000\n",
    "data_file = './train_set.csv.zip'\n",
    "train = pd.read_csv(data_file, sep='\\t', nrows=n_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据直接全局变量\n",
    "train_texts = train['text'].tolist()\n",
    "train_labels = train['label'].tolist()\n",
    "n_total = len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data2index(fold_num):\n",
    "    \"\"\"读取df，将series转换为list进行处理\"\"\"\n",
    "        \n",
    "    # 1.所有数据打乱，通过打乱列表的索引来实现 / 通过sklearn的shuffle模块？\n",
    "    index = list(range(n_total))\n",
    "    np.random.shuffle(index)\n",
    "    all_texts = []\n",
    "    all_labels = []\n",
    "    for i in index:\n",
    "        all_texts.append(train_texts[i])\n",
    "        all_labels.append(train_labels[i])\n",
    "    \n",
    "    # 2.将所有数据按照类别进行划分，通过索引实现：字典检查某个键是否存在，不存在，就创建列表，存在则往列表里添加\n",
    "    label2id = {}\n",
    "    for i in range(n_total):\n",
    "        label = str(all_labels[i])\n",
    "        # 字典检查某个键是否存在？？ 不加.keys?\n",
    "        if label not in label2id:\n",
    "            label2id[label] = [i]\n",
    "        else:\n",
    "            label2id[label].append(i)\n",
    "    \n",
    "    # 3.\n",
    "    all_index = [[] for _ in range(fold_num)]\n",
    "    for label, data in label2id.items():\n",
    "        # print(label, len(data))\n",
    "        batch_size = int(len(data) / fold_num)\n",
    "        other = len(data) - batch_size * fold_num\n",
    "        \n",
    "        # 对每个类别都进行10折划分\n",
    "        for i in range(fold_num):\n",
    "            # if判断用于赋值\n",
    "            \n",
    "            # ？\n",
    "            cur_batch_size = batch_size + 1 if i < other else batch_size\n",
    "            # print(cur_batch_size)\n",
    "            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n",
    "            \n",
    "            # 总共包含10个列表，每个列表都包含所有类别的数据\n",
    "            all_index[i].extend(batch_data)\n",
    "            # 等价于 all_index = [], all_index.append(batch_data)\n",
    "            \n",
    "            \n",
    "    return all_texts, all_labels, all_index\n",
    "\n",
    "all_texts, all_labels, all_index = all_data2index(n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 11:47:08,519 INFO: Fold lens [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]\n"
     ]
    }
   ],
   "source": [
    "def index2fold_data(all_texts, all_labels, all_index, fold_num):\n",
    "    \"\"\"这里的 texts、labels 是 fold_texts、fold_labels\"\"\"\n",
    "    \n",
    "    all_fold_data = []   \n",
    "    \n",
    "    # 4.根据每折的索引 划分出每折的数据，然后打乱\n",
    "    # 平均每折的数据量    \n",
    "    batch_size = int(n_total / fold_num)\n",
    "    other_texts = []\n",
    "    other_labels = []\n",
    "    other_num = 0\n",
    "    start = 0\n",
    "    for fold in range(fold_num):\n",
    "        # 每折的数据量\n",
    "        num = len(all_index[fold])\n",
    "        # 从所有数据索引中 索引出 每折数据 对应的text和label的索引\n",
    "        texts = [all_texts[i] for i in all_index[fold]]\n",
    "        labels = [all_labels[i] for i in all_index[fold]]\n",
    "        \n",
    "        # 如果每折的数据量 > 平均每折的数据量，对该折的数据进行缩减，只取到平均每折的数据量\n",
    "        if num > batch_size:\n",
    "            fold_texts = texts[:batch_size]\n",
    "            fold_labels = labels[:batch_size]           \n",
    "            other_texts.extend(texts[batch_size:])\n",
    "            other_labels.extend(labels[batch_size:])\n",
    "            other_num += num - batch_size\n",
    "            \n",
    "        # 如果每折的数据量 < 平均每折的数据量，则将上折剩余的数据补充到该折数据（列表的加法），直到取到平均每折的数据量\n",
    "        elif num < batch_size:\n",
    "            end = start + batch_size - num\n",
    "            # 如果上折剩余的数据量不足以补充该折数据呢，索引就会报错啊？？？？？？？？？？？？？？？\n",
    "            fold_texts = texts + other_texts[start: end]\n",
    "            fold_labels = labels + other_labels[start: end]\n",
    "            # 前面被补充过的数据不再使用\n",
    "            start = end\n",
    "        \n",
    "        # 如果每折的数据量 = 平均每折的数据量，该折的数据进行缩减，只取到平均\n",
    "        else:\n",
    "            fold_texts = texts\n",
    "            fold_labels = labels\n",
    "        \n",
    "        # 确保每折的数据量都等同于 平均每折的数据量\n",
    "        assert batch_size == len(fold_labels)\n",
    "    \n",
    "    # 那多出来的数据呢？？？？？？？？？？？？？？？？？？？？？\n",
    "    \n",
    "        # 对该折的数据进行打乱，通过列表的索引\n",
    "        fold_index = list(range(batch_size))\n",
    "        np.random.shuffle(fold_index)\n",
    "        shuffle_fold_texts = []\n",
    "        shuffle_fold_labels = []\n",
    "        for i in fold_index:\n",
    "            shuffle_fold_texts.append(fold_texts[i])\n",
    "            shuffle_fold_labels.append(fold_labels[i])\n",
    "        \n",
    "        # 将每折数据添加到 总划分数据里\n",
    "        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n",
    "        all_fold_data.append(data)\n",
    "    \n",
    "    # 记录输出 十折划分后 每折的数据量？？？\n",
    "    logging.info(\"Fold lens %s\", str([len(fold_data['label']) for fold_data in all_fold_data]))\n",
    "\n",
    "    return all_fold_data\n",
    "\n",
    "all_fold_datas = index2fold_data(all_texts, all_labels, all_index, n_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build train, dev, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_id = 9\n",
    "\n",
    "# dev\n",
    "dev_data = all_fold_datas[fold_id]\n",
    "\n",
    "# train\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for i in range(0, fold_id):\n",
    "    data = all_fold_datas[i]\n",
    "    train_texts.extend(data['text'])\n",
    "    train_labels.extend(data['label'])\n",
    "train_data = {'label': train_labels, 'text': train_texts}\n",
    "\n",
    "# test\n",
    "test_data_file = './test_a.csv.zip'\n",
    "f = pd.read_csv(test_data_file, sep='\\t')\n",
    "texts = f['text'].tolist()\n",
    "# 列表的扩充，全部标记为 0\n",
    "test_data = {'label': [0] * len(texts), 'text': texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6167 4480 736 3374 6831 6015 7255 7010 1582 2899 4893 6654 1914 6675 408 7495 1348 4559 7495 2410 2313 4464 2799 4853 1407 5491 7058 6045 2465 1110 4203 4203 2662 6167 4480 736 3374 6831 6015 7255 7010 6588 2376 1582 2899 4893 5560 6167 736 5491 1362 2662 2106 2115 3215 1939 5251 6654 1914 4464 4149 4853 3220 812 4114 6760 6983 2121 7399 23 4109 5041 2099 6675 408 3750 3771 1519 3700 1324 5814 900 6167 4480 1215 3912 1907 1939 4109 4933 6167 4480 5589 4411 5041 671 3634 6654 1914 1395 7015 900 2400 4411 3209 23 4109 5041 2099 1215 1582 5537 7419 1215 1582 5537 1110 4321 2021 4464 2799 4853 4233 23 5598 4515 4215 3317 7010 900 6654 1914 816 812 3272 1920 3750 6167 4480 1215 3641 316 4413 3226 5251 58 5702 137 2923 7160 7317 23 4109 5041 2099 6393 7212 900 6654 1914 5620 619 4464 3700 4464 5602 1519 3750 299 408 6515 6065 3370 1519 290 6235 6248 212 6571 4969 5659 264 4411 736 3374 5480 4630 133 2828 2471 900 4464 3700 5602 3370 1519 1465 5536 4936 6167 4480 4233 23 3481 550 7255 7010 900 4464 3700 4646 5602 1519 6167 736 5491 1362 2662 6093 133 3750 1465 1699 2212 5445 3700 2595 4721 6760 2463 7023 5566 4525 6122 3750 6810 3659 3370 3370 2799 1519 6122 6405 2466 6167 736 5491 1362 2662 4721 6760 2463 7023 5566 900 4464 3700 4149 4149 1519 6810 3659 3370 3370 3370 1519 1465 2042 3193 1214 2466 6167 4480 3792 2233 23 1726 366 4721 3289 7039 3396 2986 5689 900 1465 7399 2466 3272 1920 1080 2210 5598 4269 606 566 751 648 4377 3686 5938 349 3750 3501 3961 2252 2770 4691 2029 3750 6167 736 5491 1362 2662 7399 3501 2722 3099 4659 7309 6375 1641 1854 900 7399 1465 648 1582 2899 4516 3750 6167 4480 3481 1247 2042 3193 4149 5677 7078 3099 1324 1519 6122 2211 648 3792 2233 23 1726 366 2791 3800 1859 1308 900',\n",
       " '56 4411 803 6248 7403 3585 38 1635 3630 6248 913 6160 3328 5592 299 2968 3971 3255 2918 7495 1348 4559 7039 4109 4464 3659 2073 4464 4646 4853 1407 5491 7058 6045 2465 4799 7495 3819 2662 56 4411 7039 4109 307 1277 5949 3067 4464 4646 4853 1460 803 6248 7403 3585 38 1635 3630 6248 913 6160 3328 5592 1250 5202 6139 5720 3648 5370 5915 730 299 2968 2695 192 2376 2918 872 3750 6160 3328 5592 3220 6139 5720 2986 7543 3648 5370 5915 730 25 7492 2918 1264 4811 3272 5254 2130 4464 2799 1903 2073 5560 5472 3272 2289 1519 2229 2210 900 56 4411 3032 3299 465 910 3659 3370 3370 4646 1519 6832 3770 6160 3328 5592 3648 5370 4923 1099 7399 3659 3370 3370 5602 1519 340 3659 3370 3370 1324 1519 7399 7346 3630 6248 3747 2730 5803 299 2252 1702 4811 910 2318 4287 3425 648 3585 38 885 3568 3750 1080 25 7069 5502 5560 6139 5720 56 4411 670 3961 903 5292 648 3659 3370 4230 56 2106 5491 4464 1141 2106 6822 5778 4464 4464 6065 3700 56 2106 2662 3648 5370 5915 730 3750 4969 1279 5949 4741 7134 4893 5510 4557 5310 3750 3915 6909 5949 3067 2918 1264 4822 4811 3272 5254 2130 5602 1519 900 7039 4109 2400 6115 3686 5858 5949 3067 4392 1519 4464 3370 2073 7399 6122 6695 2918 872 2400 1815 1699 3750 6160 3328 5592 6139 5720 3648 5370 5915 730 340 1279 5949 4741 7134 4557 5310 1616 2595 6093 133 3750 2918 1264 4822 4811 3272 5254 2130 3659 1519 5560 5472 3272 6065 1519 2229 2210 900 6160 3328 5592 340 3032 3299 465 910 3504 2446 669 1695 4969 62 6734 299 2968 900 7039 4109 307 1277 5949 3067 7399 1036 6695 2918 872 2400 1702 3300 3750 6248 7403 3585 38 340 1344 6630 670 3961 903 5292 4969 6983 3220 6929 910 2471 3750 669 5393 3263 192 3679 7069 7055 3618 3648 5370 5915 730 4969 1279 1903 4893 5612 3099 3750 7492 5430 619 3630 3648 5948 5736 648 5430 5964 826 5413 6139 5720 7055 3648 5370 2400 4811 5134 6966 5430 1722 2348 5430 4557 5310 4128 5413 3172 5949 900 5949 3067 1702 3300 3750 6160 3328 5592 4811 7261 7408 3686 6139 5720 3648 5370 5915 730 3750 7399 4411 4181 299 3585 6093 7509 1100 648 4498 2315 900 3618 5037 619 6160 3328 5592 7492 6832 6139 5720 730 5430 2400 648 2986 7543 5619 1571 2477 6983 1722 5051 3750 5470 5328 4939 2555 197 4659 6160 3328 5592 5330 4893 7399 3630 3648 1582 3134 648 4505 3943 1277 6521 5858 1567 3220 1919 3750 872 1906 1460 4822 1264 5948 5472 2130 900 6160 3328 5592 137 4939 56 4411 7039 4109 2109 6248 4599 3354 900 3659 3370 3370 5602 1519 340 3659 3370 3370 1324 1519 3750 1465 1582 2899 648 3648 5370 4923 1099 2674 5977 7399 7346 3630 6248 3747 2730 5803 299 2252 1702 885 3568 3750 5984 4211 6093 116 3780 4993 4893 2993 6679 3360 2318 4287 3425 340 6324 6045 631 3137 4298 2318 4287 3425 900 3659 3370 3370 1324 1519 1519 751 3750 4811 910 6160 3328 5592 2318 4287 3425 6248 7403 3585 38 648 926 5801 6729 6050 7492 7477 6043 900 7039 4109 2109 6248 5915 6656 2477 1866 3461 1815 1906 6160 3328 5592 6248 7403 3585 38 3750 4969 5984 4211 6453 6535 1465 648 4599 3354 4450 5526 900 56 4411 4721 3289 4128 955 2087 5598 3354 5658 1465 648 803 1866 307 3630 6248 913 1635 4333 4430 900',\n",
       " '7256 134 7539 4679 6832 4595 1148 2402 3377 1736 4936 3659 4464 3370 3370 6104 299 5858 7495 2435 4568 5915 134 2465 2289 6357 5521 5977 4516 2210 6393 751 5977 3750 4595 1148 2402 3377 3750 4811 4261 5296 5413 5036 3634 299 1726 2786 3750 6972 6810 2252 3073 5445 3750 4679 6832 3530 3659 4464 3370 3700 6104 3750 6920 4464 6250 6065 4149 7186 3750 4936 4659 3659 4464 3370 3370 6104 299 5858 3750 6920 868 7467 2425 900']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1800个字符串（文本）\n",
    "train_data['text'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6167 4480 736 3374 6831 6015 7255 7010 1582 2899 4893 6654 1914 6675 408 7495 1348 4559 7495 2410 2313 4464 2799 4853 1407 5491 7058 6045 2465 1110 4203 4203 2662 6167 4480 736 3374 6831 6015 7255 7010 6588 2376 1582 2899 4893 5560 6167 736 5491 1362 2662 2106 2115 3215 1939 5251 6654 1914 4464 4149 4853 3220 812 4114 6760 6983 2121 7399 23 4109 5041 2099 6675 408 3750 3771 1519 3700 1324 5814 900 6167 4480 1215 3912 1907 1939 4109 4933 6167 4480 5589 4411 5041 671 3634 6654 1914 1395 7015 900 2400 4411 3209 23 4109 5041 2099 1215 1582 5537 7419 1215 1582 5537 1110 4321 2021 4464 2799 4853 4233 23 5598 4515 4215 3317 7010 900 6654 1914 816 812 3272 1920 3750 6167 4480 1215 3641 316 4413 3226 5251 58 5702 137 2923 7160 7317 23 4109 5041 2099 6393 7212 900 6654 1914 5620 619 4464 3700 4464 5602 1519 3750 299 408 6515 6065 3370 1519 290 6235 6248 212 6571 4969 5659 264 4411 736 3374 5480 4630 133 2828 2471 900 4464 3700 5602 3370 1519 1465 5536 4936 6167 4480 4233 23 3481 550 7255 7010 900 4464 3700 4646 5602 1519 6167 736 5491 1362 2662 6093 133 3750 1465 1699 2212 5445 3700 2595 4721 6760 2463 7023 5566 4525 6122 3750 6810 3659 3370 3370 2799 1519 6122 6405 2466 6167 736 5491 1362 2662 4721 6760 2463 7023 5566 900 4464 3700 4149 4149 1519 6810 3659 3370 3370 3370 1519 1465 2042 3193 1214 2466 6167 4480 3792 2233 23 1726 366 4721 3289 7039 3396 2986 5689 900 1465 7399 2466 3272 1920 1080 2210 5598 4269 606 566 751 648 4377 3686 5938 349 3750 3501 3961 2252 2770 4691 2029 3750 6167 736 5491 1362 2662 7399 3501 2722 3099 4659 7309 6375 1641 1854 900 7399 1465 648 1582 2899 4516 3750 6167 4480 3481 1247 2042 3193 4149 5677 7078 3099 1324 1519 6122 2211 648 3792 2233 23 1726 366 2791 3800 1859 1308 900\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for text, label in zip(train_data['text'], train_data['label']):\n",
    "    print(text)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] * len([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.api._v2.keras.layers' has no attribute 'LayerNormalization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-49be3bb6f0e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 新的模块\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbasic_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBasicTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\anaconda\\envs\\tf\\lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;31m# Pipelines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m from .pipelines import (\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[0mCsvPipelineDataFormat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mFeatureExtractionPipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\anaconda\\envs\\tf\\lib\\site-packages\\transformers\\pipelines.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     from .modeling_tf_auto import (\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mTFAutoModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mTFAutoModelForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\anaconda\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     91\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodeling_tf_gpt2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFGPT2LMHeadModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTFGPT2Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m from .modeling_tf_mobilebert import (\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[0mTFMobileBertForMaskedLM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mTFMobileBertForMultipleChoice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\anaconda\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_mobilebert.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mTFLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v2.keras.layers' has no attribute 'LayerNormalization'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# 新的模块 transformers\n",
    "from transformers import BasicTokenizer\n",
    "basic_tokenizer = BasicTokenizer()\n",
    "\n",
    "# 使用以前的tensorflow（2.0.0 alpha）和keras（2.3.1）版本时，会报错：AttributeError: module 'tensorflow.python.keras.api._v2.keras.layers' has no attribute 'LayerNormalization'\n",
    "# 与transformers的版本无关，通过pip uninstall 原来的tf，再install 2.1.0版本的tf，就可以了\n",
    "\n",
    "# 类似的问题：https://blog.csdn.net/qq_43486915/article/details/101475856\n",
    "# 版本对应查看：https://docs.floydhub.com/guides/environments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0, '[UNK]': 1, 'aa': 2, 'scs': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse = lambda x: dict(zip(x, range(len(x))))\n",
    "_id2word = ['[PAD]', '[UNK]', 'aa', 'scs']\n",
    "reverse(_id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试，类 Vocab 的空白处再定义的时候就运行了\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# 新的模块\n",
    "from transformers import BasicTokenizer\n",
    "basic_tokenizer = BasicTokenizer()\n",
    "\n",
    "class Vocab():\n",
    "    \n",
    "    # 测试初始化类时是否运行    \n",
    "    print('测试，类 Vocab 的空白处再定义的时候就运行了')\n",
    "    \n",
    "    def __init__(self, train_data):\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 __init__ 运行了')\n",
    "        \n",
    "        # 在所有预料中，最少出现5次才计数\n",
    "        self.min_count = 5\n",
    "        # ？？？？？？？？？？？？\n",
    "        self.pad = 0\n",
    "        self.unk = 1\n",
    "        # 所以word_size都是 4335+2\n",
    "        self._id2word = ['[PAD]', '[UNK]']\n",
    "        self._id2extword = ['[PAD]', '[UNK]']\n",
    "\n",
    "        self._id2label = []\n",
    "        self.target_names = []\n",
    "        \n",
    "        # 处理传入的参数，可以在这调用后面的函数！！！！！！！！！！ \n",
    "        self.build_vocab(train_data)\n",
    "        \n",
    "        # zip 对列表 x 里所有的单个字符迭代，目的是对每个字符进行编码 0 1 2 ...\n",
    "        reverse = lambda x: dict(zip(x, range(len(x))))\n",
    "        # 是个字典，键是 值是\n",
    "        self._word2id = reverse(self._id2word)\n",
    "        self._label2id = reverse(self._id2label)\n",
    "        \n",
    "        \n",
    "        # 可以调用后面的函数 word_size、label_size，因为没有参数，所以不加括号吗？？？\n",
    "        logging.info(\"Build vocab: words %d, labels %d.\" % (self.word_size, self.label_size))\n",
    "\n",
    "    def build_vocab(self, data):\n",
    "                    \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 build_vocab 运行了')\n",
    "        \n",
    "        # 这个新的属性可以在其他地方调用吗？？？？？？？？？？？？？？？？？？？？？\n",
    "        self.word_counter = Counter()\n",
    "\n",
    "        for text in data['text']:\n",
    "            words = text.split()\n",
    "            # 不需要if判断？？？？？？？？？？？？？？？？？？？\n",
    "            for word in words:\n",
    "                self.word_counter[word] += 1\n",
    "        \n",
    "        # 是遍历全部吗？？？？？？？？？？？？？？？？？？？？？？？？？？？\n",
    "        for word, count in self.word_counter.most_common():\n",
    "            # 出现次数不到5的word，不添加\n",
    "            if count >= self.min_count:\n",
    "                self._id2word.append(word)\n",
    "        \n",
    "        # 灵活变化！！！！！！！！！！！！！！\n",
    "        label2name = {0: '科技', 1: '股票', 2: '体育', 3: '娱乐', 4: '时政', 5: '社会', 6: '教育', 7: '财经',\n",
    "                      8: '家居', 9: '游戏', 10: '房产', 11: '时尚', 12: '彩票', 13: '星座'}\n",
    "        \n",
    "        # 不同于word？？？？？？？？？？？？？？？？？？？？？？？？？？？\n",
    "        self.label_counter = Counter(data['label'])\n",
    "        \n",
    "        # 针对每个类别，根据字典的键（类别，int）取值\n",
    "        for label in range(len(self.label_counter)):\n",
    "            # count的作用，和前面的循环不接啊？？？？？？？？？？？？？？？？？？？？？\n",
    "            count = self.label_counter[label]\n",
    "            self._id2label.append(label)\n",
    "            self.target_names.append(label2name[label])\n",
    "\n",
    "\n",
    "    def load_pretrained_embs(self, embfile):\n",
    "                    \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 load_pretrained_embs 运行了')\n",
    "        \n",
    "        # embfile 是 word2vec.txt文件，第一行是文件的 shape（n_examples, n_features) \n",
    "        with open(embfile, encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            # 默认的分隔符是空格？？？？？？？？？\n",
    "            items = lines[0].split()\n",
    "            # n_examples, n_features = 4337, 100\n",
    "            word_count, embedding_dim = int(items[0]), int(items[1])\n",
    "        \n",
    "        # 嵌入层添加数据，文件的第一行是shape！！！！！\n",
    "        # self._id2extword 的含义是所有的字符（后面的代码还会往里添加） 嵌入层加上它的作用？？？？？？？？？？？\n",
    "        index = len(self._id2extword)\n",
    "        embeddings = np.zeros((word_count + index, embedding_dim))\n",
    "        for line in lines[1:]:\n",
    "            values = line.split()\n",
    "            # 第一个数值是哪个字符（字符代码）\n",
    "            self._id2extword.append(values[0])\n",
    "            vector = np.array(values[1:], dtype='float64')\n",
    "            \n",
    "            # 为什么都要加到嵌入层的第2行上，第一行都是0 ？？？？？？？？？？？？？？？？？？？\n",
    "            embeddings[self.unk] += vector\n",
    "            # 刚开始 index=2，所以从第三行开始填充（embeddings层中 index的部分不填充）\n",
    "            # 不断更改嵌入层里 某层的数值，index不断增加，填充 embeddings层中 word_count的部分\n",
    "            embeddings[index] = vector\n",
    "            index += 1\n",
    "            \n",
    "        # 第二行加了 word_count 次，把 word2vec文件里的所有向量都加起来了，最后平均下\n",
    "        embeddings[self.unk] = embeddings[self.unk] / word_count\n",
    "        # np.std不说明axis的话，是求所有元素的std，但是嵌入层对应 extword 的部分还有很多行（除了第二行）的数据都是0啊？？？？？？？？\n",
    "        embeddings = embeddings / np.std(embeddings)\n",
    "        \n",
    "        # ？？？？？？？？？？？？？？？？？？？？？？？？？\n",
    "        reverse = lambda x: dict(zip(x, range(len(x))))\n",
    "        # 这里新创建的属性，被用在了后面的方法里面！！！！！！！！！！！！！！！！！！\n",
    "        self._extword2id = reverse(self._id2extword)\n",
    "        \n",
    "        #print(set(self._id2extword), self._id2extword)   \n",
    "        print(len(set(self._id2extword)), len(self._id2extword))    \n",
    "        \n",
    "        # 生成字典时，相同的键值会合并！！！！！！！！！！！！！！！！\n",
    "        assert len(set(self._id2extword)) == len(self._id2extword)\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "    # 对每个字符进行编码！！！！！！！！\n",
    "    \n",
    "    # 三个转化函数，除了被转化对象 self._word2id  self._extword2id  self._label2id 不一样外，其他都一致\n",
    "    def word2id(self, xs):\n",
    "        \"\"\"xs是？？？？？？？？？？？？？？？？？？？？\"\"\"\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 word2id 运行了')\n",
    "        \n",
    "        # 判断类型是否为 list，返回 Bool (参考：https://www.runoob.com/python/python-func-isinstance.html)\n",
    "        if isinstance(xs, list):\n",
    "            # 字典的 get 方法, x （键）存在则返回值，不存在则返回 1（参考：https://www.runoob.com/python/att-dictionary-get.html）\n",
    "            return [self._word2id.get(x, self.unk) for x in xs]\n",
    "        # 不是 list，单个元素？？？？？？？？？？？？？？？？\n",
    "        return self._word2id.get(xs, self.unk)\n",
    "\n",
    "    def extword2id(self, xs):\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 extword2id 运行了')\n",
    "        \n",
    "        if isinstance(xs, list):\n",
    "            return [self._extword2id.get(x, self.unk) for x in xs]\n",
    "        return self._extword2id.get(xs, self.unk)\n",
    "\n",
    "    def label2id(self, xs):\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 label2id 运行了')\n",
    "        \n",
    "        if isinstance(xs, list):\n",
    "            return [self._label2id.get(x, self.unk) for x in xs]\n",
    "        return self._label2id.get(xs, self.unk)\n",
    "\n",
    "    @property\n",
    "    def word_size(self):\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 word_size 运行了')\n",
    "        \n",
    "        return len(self._id2word)\n",
    "    \n",
    "    # logging没用到！！！！！！！！！！\n",
    "    @property\n",
    "    def extword_size(self):\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 extword_size 运行了')\n",
    "        \n",
    "        return len(self._id2extword)\n",
    "\n",
    "    @property\n",
    "    def label_size(self):\n",
    "        \n",
    "        # 测试初始化类时是否运行    \n",
    "        print('测试，类 Vocab，函数 label_size 运行了')\n",
    "        \n",
    "        return len(self._id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例初始化时传入了参数，必会运行 __init__() 函数，不会运行开头的空白处，后面的方法中，__init__中没有提及的，都不会运行！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当读入的数据是前一万条时，显示的是4337，label=14，但是后面可以加载5978的词向量，**这里的4337和后面的5978之间的关系？？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试，类 Vocab，函数 __init__ 运行了\n",
      "测试，类 Vocab，函数 build_vocab 运行了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-29 10:48:37,650 INFO: Build vocab: words 5996, labels 14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试，类 Vocab，函数 word_size 运行了\n",
      "测试，类 Vocab，函数 label_size 运行了\n",
      "Wall time: 59.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = Vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocab at 0x1394c0c1278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab不是类返回的变量，就是类本身，和以前的模型初始化一样，可以使用类中的一些方法处理变量（clf= model(), clf.fit()）！！！！！！！\n",
    "# 类初始化时，不会再返回传入的参数 train_data\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(np.random.randn(3,2,2))\n",
    "b = torch.Tensor(np.random.randn(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相乘时，首尾对应，并且首尾对应的维度都会消失（3+1-2 --> 2）！！！！！！！！！！！\n",
    "\n",
    "乘以一维张量的，会消除一个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TypeError: matmul(): argument 'input' (position 1) must be Tensor, not numpy.ndarray\n",
    "torch.matmul(a, b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首尾对应的维度都会消失（3+2-2 --> 3）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.Tensor(np.random.randn(3,2,2))\n",
    "d = torch.Tensor(np.random.randn(2,5))\n",
    "torch.matmul(c, d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(-1e32)< 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build word encoder\n",
    "\n",
    "TextCNN的论文里，也没提到Attention word encoder啊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 双通道（生成的word2vec + 训练的embed-vec）\n",
    "\n",
    "通道二\n",
    "\n",
    "**为什么第一层全是0，第二层又有什么特殊的含义？？？？？？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试，类 Vocab，函数 load_pretrained_embs 运行了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-26 12:47:46,161 INFO: Load extword embed: words 4337, dims 100.\n"
     ]
    }
   ],
   "source": [
    "word2vec_path = './emb/word2vec.txt'\n",
    "# 加载训练好的向量 (4335, 100)!!!!!!!!!!\n",
    "extword_embed = vocab.load_pretrained_embs(word2vec_path)\n",
    "# shape (n_examples, n_features) = (size, dims)\n",
    "extword_size, word_dims = extword_embed.shape\n",
    "logging.info(\"Load extword embed: words %d, dims %d.\" % (extword_size, word_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0446, -0.1373,  0.2730,  ...,  0.1510,  0.1139,  0.1337],\n",
       "        [ 0.2177,  1.9787,  0.2219,  ...,  0.3089, -0.5231, -1.7075],\n",
       "        ...,\n",
       "        [ 2.4204,  0.6877,  0.4054,  ...,  0.2642,  0.4043, -1.1890],\n",
       "        [-0.6415,  0.0572,  1.6200,  ...,  2.4325,  0.2091,  0.8547],\n",
       "        [ 0.3198,  0.9130, -1.3433,  ...,  0.5710, -1.0892,  0.0587]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 额外的嵌入层，数值为训练过的 word2vec\n",
    "extword_embed1 = nn.Embedding(extword_size, word_dims, padding_idx=0)\n",
    "extword_embed1.weight.data.copy_(torch.from_numpy(extword_embed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不能直接对层进行索引，否则报错。但是前面的嵌入层为何可以？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4337, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0446, -0.1373,  0.2730, -0.4079,  0.2474, -0.1248, -0.4053, -0.4359,\n",
       "          0.0049, -0.1241, -0.0393,  0.0532,  0.5420, -0.5532, -0.1025,  0.0317,\n",
       "          0.2938, -0.3270, -0.4014,  0.0149, -0.4539,  0.6132,  0.1579,  0.1789,\n",
       "         -0.2171, -0.1059,  0.3820,  0.2442,  0.4265,  0.1172,  0.1849,  0.1007,\n",
       "         -0.1224, -0.2898, -0.3528,  0.3965, -0.1996, -0.0150, -0.0195, -0.0043,\n",
       "          0.2354, -0.4869, -0.1527, -0.2648,  0.1198, -0.5091, -0.3110, -0.4006,\n",
       "         -0.0147,  0.2819, -0.2818, -0.2920,  0.5137, -0.2268, -0.1502,  0.0889,\n",
       "          0.3805, -0.0822, -0.3526,  0.4258,  0.1954,  0.2357, -0.1696,  0.5199,\n",
       "         -0.3998, -0.1453,  0.1305, -0.0392,  0.4646,  0.4453, -0.2986, -0.3260,\n",
       "         -0.1619, -0.0399, -0.2811,  0.0503,  0.0778,  0.0278,  0.0642,  0.1260,\n",
       "         -0.1384,  0.3869,  0.1066,  0.2240, -0.1180, -0.0128, -0.2327,  0.2076,\n",
       "          0.2380,  0.0274, -0.7335,  0.2032, -0.3577,  0.0566,  0.1535, -0.0803,\n",
       "         -0.5303,  0.1510,  0.1139,  0.1337],\n",
       "        [ 0.2177,  1.9787,  0.2219,  1.5648,  0.1534,  0.1120, -0.2532, -0.7988,\n",
       "          1.1192, -0.8178, -0.4968, -0.4788,  1.1548, -0.4397,  1.0931, -0.8851,\n",
       "         -0.7525,  1.0634,  0.0677,  0.9383,  0.8884, -1.0119, -0.5163,  0.1797,\n",
       "         -0.2575, -2.0116, -0.8283,  1.0274,  1.7035, -0.4152,  1.3408, -1.3790,\n",
       "         -0.6207, -1.1577,  0.4254, -1.5718,  0.6961, -1.3670,  0.2250,  1.0812,\n",
       "          0.5423, -0.0528,  1.6583,  1.6075, -0.5014,  0.9257, -0.2141,  1.2271,\n",
       "         -0.0144, -0.6195,  1.4436,  0.2348, -0.1662,  1.7543,  0.7094,  0.8995,\n",
       "         -1.8981,  1.0970,  0.6849, -1.5587,  0.5428,  0.4414,  0.3833, -0.7872,\n",
       "          1.1192, -1.7393,  1.1778,  0.7365, -1.0933, -0.8651,  0.1455,  0.5528,\n",
       "          0.8316, -1.5709, -0.0324, -2.7490, -0.2532, -0.6318,  0.8126,  0.7028,\n",
       "         -1.6127,  0.9313,  0.1455, -0.2008, -0.0764, -0.9203, -0.2208,  0.4012,\n",
       "         -0.7904,  0.6070, -0.5905, -0.7675,  1.8109, -0.4968,  0.5330,  1.6855,\n",
       "          0.4902,  0.3089, -0.5231, -1.7075]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(extword_embed1.weight.data.shape)\n",
    "extword_embed1.weight.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入前面的vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#word2vec_path = './emb/word2vec.txt'\n",
    "word2vec_path = './emb/word2vec_all.txt'\n",
    "# 随机保留 or 舍弃 0.15 ？？？？\n",
    "dropout = 0.15\n",
    "\n",
    "class WordCNNEncoder(nn.Module):\n",
    "    def __init__(self, vocab):\n",
    "        \"\"\"传入前面的 Vocab 类，在额外嵌入层时使用方法，加载训练好的 word2vec\"\"\"\n",
    "        \n",
    "        # 为什么都得继承一下？？？？？？？？？？？？？？？？？？\n",
    "        super(WordCNNEncoder, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.word_dims = 100\n",
    "        \n",
    "        # word 对应的 Embedding 层的参数需要后面训练（forward），padding_idx（保持句子长度一致） 0填充？？？？？？？？\n",
    "        # vocab.word_size 即不重复的单词的数目 4337 = 4335 + 2\n",
    "        self.word_embed = nn.Embedding(vocab.word_size, self.word_dims, padding_idx=0)\n",
    "        \n",
    "        # 前面训练过的词向量（word2vec）作为额外的嵌入层，参数都是训练好的！！！！\n",
    "        extword_embed = vocab.load_pretrained_embs(word2vec_path)\n",
    "        extword_size, word_dims = extword_embed.shape   # (word_size, word_dims) = （4335+2， 100）\n",
    "        logging.info(\"Load extword embed: words %d, dims %d.\" % (extword_size, word_dims))   \n",
    "        self.extword_embed = nn.Embedding(extword_size, word_dims, padding_idx=0)\n",
    "        self.extword_embed.weight.data.copy_(torch.from_numpy(extword_embed))\n",
    "        # requires_grad ？？？？？？？？？？？？？？？\n",
    "        self.extword_embed.weight.requires_grad = False\n",
    "             \n",
    "        # 不同的kernel可以获取不同范围内词的关系，获得的是纵向的差异信息，\n",
    "        # 即类似于n-gram window，也就是在一个句子中不同范围的词出现会带来什么信息。比如可以使用3,4,5个词数分别作为卷积核的大小\n",
    "        self.filter_sizes = [2, 3, 4]  \n",
    "        self.out_channel = 100\n",
    "        # 整个句子（嵌入层的一行）都被卷积\n",
    "        input_size = self.word_dims\n",
    "        # 3个卷积层的列表，对应不同尺寸的卷积核\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, self.out_channel, (filter_size, input_size), bias=True)\n",
    "                                    for filter_size in self.filter_sizes])\n",
    "\n",
    "    def forward(self, word_ids, extword_ids):\n",
    "        \"\"\"word_ids 即 model 类中的 batch_inputs， shape = (batch_size * max_doc_len, max_sent_len) =（sen_num，sent_len）\"\"\"\n",
    "        # word_ids、extword_ids: （sen_num，sent_len） \n",
    "        \n",
    "        # sent层？？？？？？？\n",
    "        sen_num, sent_len = word_ids.shape\n",
    "        \n",
    "        # 向嵌入层内传入二维张量参数，变成三个维度 \n",
    "        word_embed = self.word_embed(word_ids)        # （sen_num，sent_len，word_dims=100） \n",
    "        \n",
    "        # 不是已经有网络参数了吗，怎么还要传入参数？？？？？？？？？？？\n",
    "        extword_embed = self.extword_embed(extword_ids)\n",
    "        # 名字对应 batch~！！！！！！！！！！！！！！！！！！！！\n",
    "        batch_embed = word_embed + extword_embed\n",
    "        \n",
    "        # Dropout后，维度不变\n",
    "        if self.training:\n",
    "            batch_embed = self.dropout(batch_embed)     # （sen_num，sent_len，word_dims） \n",
    "        \n",
    "        # unsqueeze 增加维度（相当于view），参数 1 是指增加到第二个维度，因为后面conv层要求的输入是4维张量\n",
    "        batch_embed.unsqueeze_(1)  # （sen_num，1，sent_len，100）\n",
    "        \n",
    "        # 使用不同的卷积核，对应不同的卷积层\n",
    "        pooled_outputs = []\n",
    "        for i in range(len(self.filter_sizes)):\n",
    "            # 卷积后得到的结果是一个vector，其 shape=(sentence_len - filter_window_size + 1, 1) \n",
    "            filter_height = sent_len - self.filter_sizes[i] + 1\n",
    "\n",
    "            conv = self.convs[i](batch_embed)\n",
    "            \n",
    "            # 维度应该是不变的\n",
    "            hidden = F.relu(conv)  # （sen_num，out_channel，filter_height，1）\n",
    "            \n",
    "            # 对应conv层是四维张量的输出，所以用二维池化（4维输入要求，一维池化是三维输入要求）  \n",
    "            mp = nn.MaxPool2d((filter_height, 1))   # (filter_height, filter_width) = (filter_height, 1)\n",
    "            \n",
    "            # Max Pooling Over Time（1-max pooling）从卷积层一系列特征值中取最强的那个值\n",
    "            # 四维张量化成二维张量，mp(hidden).shape = （sen_num，out_channel，1，1）\n",
    "            pooled = mp(hidden).reshape(sen_num, self.out_channel)  # （sen_num，out_channel）\n",
    "            pooled_outputs.append(pooled) \n",
    "        \n",
    "        # 在第二个维度把这几个二维张量拼起来，reps 是？？？？？？？？？？？？？\n",
    "        reps = torch.cat(pooled_outputs, dim=1)   # （sen_num，total_out_channel = out_channel * 3）\n",
    "\n",
    "        if self.training:\n",
    "            reps = self.dropout(reps)\n",
    "\n",
    "        return reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MaxPool2d in module torch.nn.modules.pooling:\n",
      "\n",
      "class MaxPool2d(_MaxPoolNd)\n",
      " |  Applies a 2D max pooling over an input signal composed of several input\n",
      " |  planes.\n",
      " |  \n",
      " |  In the simplest case, the output value of the layer with input size :math:`(N, C, H, W)`,\n",
      " |  output :math:`(N, C, H_{out}, W_{out})` and :attr:`kernel_size` :math:`(kH, kW)`\n",
      " |  can be precisely described as:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\begin{aligned}\n",
      " |          out(N_i, C_j, h, w) ={} & \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n",
      " |                                  & \\text{input}(N_i, C_j, \\text{stride[0]} \\times h + m,\n",
      " |                                                 \\text{stride[1]} \\times w + n)\n",
      " |      \\end{aligned}\n",
      " |  \n",
      " |  If :attr:`padding` is non-zero, then the input is implicitly zero-padded on both sides\n",
      " |  for :attr:`padding` number of points. :attr:`dilation` controls the spacing between the kernel points.\n",
      " |  It is harder to describe, but this `link`_ has a nice visualization of what :attr:`dilation` does.\n",
      " |  \n",
      " |  The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
      " |  \n",
      " |      - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
      " |      - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
      " |        and the second `int` for the width dimension\n",
      " |  \n",
      " |  Args:\n",
      " |      kernel_size: the size of the window to take a max over\n",
      " |      stride: the stride of the window. Default value is :attr:`kernel_size`\n",
      " |      padding: implicit zero padding to be added on both sides\n",
      " |      dilation: a parameter that controls the stride of elements in the window\n",
      " |      return_indices: if ``True``, will return the max indices along with the outputs.\n",
      " |                      Useful for :class:`torch.nn.MaxUnpool2d` later\n",
      " |      ceil_mode: when True, will use `ceil` instead of `floor` to compute the output shape\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C, H_{in}, W_{in})`\n",
      " |      - Output: :math:`(N, C, H_{out}, W_{out})`, where\n",
      " |  \n",
      " |        .. math::\n",
      " |            H_{out} = \\left\\lfloor\\frac{H_{in} + 2 * \\text{padding[0]} - \\text{dilation[0]}\n",
      " |                  \\times (\\text{kernel\\_size[0]} - 1) - 1}{\\text{stride[0]}} + 1\\right\\rfloor\n",
      " |  \n",
      " |        .. math::\n",
      " |            W_{out} = \\left\\lfloor\\frac{W_{in} + 2 * \\text{padding[1]} - \\text{dilation[1]}\n",
      " |                  \\times (\\text{kernel\\_size[1]} - 1) - 1}{\\text{stride[1]}} + 1\\right\\rfloor\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # pool of square window of size=3, stride=2\n",
      " |      >>> m = nn.MaxPool2d(3, stride=2)\n",
      " |      >>> # pool of non-square window\n",
      " |      >>> m = nn.MaxPool2d((3, 2), stride=(2, 1))\n",
      " |      >>> input = torch.randn(20, 16, 50, 32)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _link:\n",
      " |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MaxPool2d\n",
      " |      _MaxPoolNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _MaxPoolNd:\n",
      " |  \n",
      " |  __init__(self, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _MaxPoolNd:\n",
      " |  \n",
      " |  __constants__ = ['kernel_size', 'stride', 'padding', 'dilation', 'retu...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self, requires_grad=True)\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 为什么keras实现那里用的是 MaxPool1d？？？？？？？？？\n",
    "help(nn.MaxPool2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build sent encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_hidden_size = 256\n",
    "sent_num_layers = 2\n",
    "\n",
    "\n",
    "class SentEncoder(nn.Module):\n",
    "    def __init__(self, sent_rep_size):\n",
    "        # ？？？？？？？？\n",
    "        super(SentEncoder, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 加入lstm层，论文中也没有啊，lstm层的参数的含义？？？？？？？？？？？？？？\n",
    "        self.sent_lstm = nn.LSTM(\n",
    "            input_size=sent_rep_size,     # 输入的特征维度 300\n",
    "            hidden_size=sent_hidden_size, # 隐藏层的特征维度 256\n",
    "            num_layers=sent_num_layers,   # lstm隐藏层的层数 2\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "    def forward(self, sent_reps, sent_masks):\n",
    "        # sent_reps:  b x doc_len x sent_rep_size （batch_size, max_doc_len，sent_rep_size ) 可以reshape为（sent_num， sent_rep_size ）\n",
    "        # sent_masks: b x doc_len\n",
    "        \n",
    "        # 返回的参数不止一个\n",
    "        sent_hiddens, _ = self.sent_lstm(sent_reps)  # （b，doc_len，hidden*2）\n",
    "        sent_hiddens = sent_hiddens * sent_masks.unsqueeze(2)\n",
    "\n",
    "        if self.training:\n",
    "            sent_hiddens = self.dropout(sent_hiddens)\n",
    "\n",
    "        return sent_hiddens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build Attention\n",
    "\n",
    "torch在参数初始化时，可以先给定shape，再给数值！！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "masked_fill_(...)\n",
      "    masked_fill_(mask, value)\n",
      "    \n",
      "    Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "    True. The shape of :attr:`mask` must be\n",
      "    :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "    tensor.\n",
      "    \n",
      "    Args:\n",
      "        mask (BoolTensor): the boolean mask\n",
      "        value (float): the value to fill in with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.Tensor.masked_fill_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - torch.Tensor([1, 0])).bool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类里的 nn.Module 是？？？？？？？？？？？？？？？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是不是因为直接生成的tensor的参数**不能进行梯度训练**，所以先定义形状，再给数值？？ ？？？？？？？？\n",
    "\n",
    "修改下行不？\n",
    "\n",
    "https://www.jianshu.com/p/a105858567df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden_size_ = 256\n",
    "hidden_size_ = sent_hidden_size_ * 2\n",
    "weight = torch.normal(mean=0, std=0.05, size=(hidden_size_, hidden_size_))\n",
    "weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.zeros(hidden_size_)\n",
    "bias.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = torch.normal(0.0, 0.05, (hidden_size_, )) \n",
    "query.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.requires_grad = True\n",
    "weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        # 超类,继承自己，没有从模块里啊 ？？？？？？？？？？？？？\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        # hidden_size 为 Attention 层的隐藏单元数，为sent层中lstm层的隐藏单元数的两倍！！！！！！！！\n",
    "        \n",
    "        # 参数的初始化和 tf 不同，没有torch.normal，直接一步到位吗？？？？？？？\n",
    "        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.weight.data.normal_(mean=0.0, std=0.05)\n",
    "        \n",
    "        # 没有 torch.zeros ，为何不torch.Tensor(b) ？？？？？\n",
    "        self.bias = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        b = np.zeros(hidden_size, dtype=np.float32)\n",
    "        self.bias.data.copy_(torch.from_numpy(b))\n",
    "        \n",
    "        # query ？？？？\n",
    "        self.query = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        self.query.data.normal_(mean=0.0, std=0.05)\n",
    "\n",
    "    def forward(self, batch_hidden, batch_masks):\n",
    "        # batch_hidden: (b，len，hidden_size=2 * hidden_size of lstm）\n",
    "        # batch_masks:  （b，len）\n",
    "\n",
    "        # linear\n",
    "        key = torch.matmul(batch_hidden, self.weight) + self.bias  # （b，len，hidden） \n",
    "\n",
    "        # compute attention\n",
    "        # query 是一维张量，所以key会减少一个维度\n",
    "        outputs = torch.matmul(key, self.query)  # （b，len）\n",
    "        \n",
    "        # 将outputs中，对应True的位置，用float(-1e32)填充\n",
    "        # https://blog.csdn.net/jianyingyao7658/article/details/103382654\n",
    "        masked_outputs = outputs.masked_fill((1 - batch_masks).bool(), float(-1e32))  # （b，len）\n",
    "        \n",
    "        # 多分类，softmax 函数激活后再输出，dim=1 是对每一行进行 softmax 激活 ？？？？\n",
    "        attn_scores = F.softmax(masked_outputs, dim=1)  # （b，len）\n",
    "\n",
    "        # 对于全零向量，-1e32的结果为 1/len, -inf为nan, 额外补0 ????????????????????????????\n",
    "        masked_attn_scores = attn_scores.masked_fill((1 - batch_masks).bool(), 0.0)   # （b，len）\n",
    "\n",
    "        # sum weighted sources ？？？？？？？？？？\n",
    "        # 批数据之间的矩阵乘法：（b，1, len） 与（b，len，hidden）的 torch.bmm 结果为 （b，1，hidden）\n",
    "        batch_outputs = torch.bmm(masked_attn_scores.unsqueeze(1), key).squeeze(1)  # （b，1，hidden） 降维为（b，hidden）\n",
    "\n",
    "        return batch_outputs, attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.mm  torch.matmul  torch.bmm 之间的区别**\n",
    "\n",
    "https://blog.csdn.net/ganxiwu9686/article/details/95204013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.view()即tf.reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试，类 Vocab，函数 word_size 运行了\n",
      "测试，类 Vocab，函数 load_pretrained_embs 运行了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-29 10:48:48,719 INFO: Load extword embed: words 5978, dims 100.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5978 5978\n"
     ]
    }
   ],
   "source": [
    "word_encoder = WordCNNEncoder(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordCNNEncoder(\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      "  (word_embed): Embedding(5996, 100, padding_idx=0)\n",
      "  (extword_embed): Embedding(5978, 100, padding_idx=0)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(word_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordCNNEncoder(\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      "  (word_embed): Embedding(4337, 100, padding_idx=0)\n",
      "  (extword_embed): Embedding(4337, 100, padding_idx=0)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(word_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('word_embed.weight',\n",
       "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                      [-0.1352, -0.3804, -0.0035,  ..., -1.3826,  0.5351,  1.0329],\n",
       "                      [ 0.9951, -0.3827,  2.6233,  ..., -1.0207,  1.9715,  0.1106],\n",
       "                      ...,\n",
       "                      [-0.5620,  0.3514, -0.4366,  ...,  1.6153, -0.0592,  0.2314],\n",
       "                      [ 1.2819,  2.1936,  0.3616,  ...,  0.0555,  0.8765, -0.8002],\n",
       "                      [-1.5785, -0.2578, -1.2632,  ...,  1.9032,  0.1489, -1.2119]])),\n",
       "             ('extword_embed.weight',\n",
       "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                      [-0.0446, -0.1373,  0.2730,  ...,  0.1510,  0.1139,  0.1337],\n",
       "                      [ 0.2177,  1.9787,  0.2219,  ...,  0.3089, -0.5231, -1.7075],\n",
       "                      ...,\n",
       "                      [ 2.4204,  0.6877,  0.4054,  ...,  0.2642,  0.4043, -1.1890],\n",
       "                      [-0.6415,  0.0572,  1.6200,  ...,  2.4325,  0.2091,  0.8547],\n",
       "                      [ 0.3198,  0.9130, -1.3433,  ...,  0.5710, -1.0892,  0.0587]])),\n",
       "             ('convs.0.weight',\n",
       "              tensor([[[[ 0.0513, -0.0392, -0.0210,  ..., -0.0148, -0.0283, -0.0288],\n",
       "                        [ 0.0320, -0.0690, -0.0075,  ...,  0.0536, -0.0545, -0.0411]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0271, -0.0569,  0.0283,  ..., -0.0410,  0.0319, -0.0027],\n",
       "                        [ 0.0373, -0.0326,  0.0084,  ...,  0.0387, -0.0051,  0.0554]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0124, -0.0699,  0.0171,  ..., -0.0641,  0.0599,  0.0296],\n",
       "                        [ 0.0321,  0.0313, -0.0232,  ..., -0.0673, -0.0102,  0.0256]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0101,  0.0439,  0.0501,  ...,  0.0267, -0.0369, -0.0668],\n",
       "                        [-0.0582, -0.0345, -0.0249,  ..., -0.0286, -0.0686,  0.0481]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0701, -0.0634, -0.0286,  ..., -0.0376, -0.0087,  0.0118],\n",
       "                        [-0.0209,  0.0465,  0.0532,  ...,  0.0460,  0.0359,  0.0306]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0636,  0.0190, -0.0287,  ...,  0.0101, -0.0316, -0.0339],\n",
       "                        [-0.0367,  0.0021, -0.0455,  ..., -0.0017, -0.0050,  0.0549]]]])),\n",
       "             ('convs.0.bias',\n",
       "              tensor([-0.0220,  0.0157, -0.0528, -0.0658, -0.0253, -0.0302, -0.0554,  0.0535,\n",
       "                      -0.0167, -0.0699, -0.0170,  0.0005, -0.0069, -0.0150, -0.0142, -0.0128,\n",
       "                      -0.0504, -0.0451,  0.0401,  0.0458,  0.0360,  0.0372,  0.0333, -0.0444,\n",
       "                       0.0581,  0.0180, -0.0262,  0.0672,  0.0656,  0.0598,  0.0537,  0.0671,\n",
       "                      -0.0386, -0.0345, -0.0604, -0.0573,  0.0027, -0.0684,  0.0484,  0.0066,\n",
       "                       0.0063, -0.0359, -0.0670, -0.0464,  0.0205, -0.0137, -0.0226,  0.0253,\n",
       "                      -0.0128,  0.0673, -0.0603,  0.0322,  0.0528, -0.0020, -0.0422,  0.0251,\n",
       "                      -0.0010, -0.0396, -0.0462, -0.0656,  0.0198, -0.0130,  0.0674,  0.0019,\n",
       "                       0.0490, -0.0422,  0.0033,  0.0063,  0.0032, -0.0076, -0.0352,  0.0099,\n",
       "                       0.0354,  0.0700,  0.0634,  0.0642, -0.0262, -0.0540, -0.0013, -0.0283,\n",
       "                      -0.0270, -0.0453, -0.0428, -0.0025, -0.0634, -0.0521,  0.0117, -0.0104,\n",
       "                       0.0479, -0.0075, -0.0162,  0.0122,  0.0688, -0.0227,  0.0545,  0.0422,\n",
       "                      -0.0506, -0.0301,  0.0257,  0.0363])),\n",
       "             ('convs.1.weight',\n",
       "              tensor([[[[-5.6716e-02, -5.4520e-02,  4.7394e-02,  ...,  5.3057e-02,\n",
       "                          2.3223e-03,  4.3600e-02],\n",
       "                        [-5.1246e-02,  4.1496e-02,  4.1333e-02,  ...,  5.1012e-02,\n",
       "                         -3.8865e-02, -4.2384e-02],\n",
       "                        [-1.8132e-02, -4.6406e-02,  5.2645e-02,  ..., -1.3792e-03,\n",
       "                         -2.8816e-02, -1.2643e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7610e-02, -2.8728e-02,  3.0960e-02,  ...,  4.9913e-02,\n",
       "                          2.2685e-02,  1.1208e-02],\n",
       "                        [-2.1563e-02, -4.7843e-02, -1.8072e-02,  ...,  4.0477e-02,\n",
       "                         -5.5858e-02, -5.3029e-02],\n",
       "                        [-5.2622e-02, -4.4930e-02, -1.3372e-02,  ...,  4.0154e-02,\n",
       "                          4.3273e-04,  4.8055e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6628e-05, -4.5039e-02,  4.0294e-02,  ..., -4.1355e-02,\n",
       "                          1.7308e-02,  5.4621e-03],\n",
       "                        [-2.4061e-02, -1.5853e-02,  3.7839e-02,  ..., -4.3246e-02,\n",
       "                          5.6183e-02, -2.5238e-02],\n",
       "                        [ 5.7423e-02, -5.4671e-02,  3.5236e-02,  ...,  2.2812e-02,\n",
       "                         -3.5250e-02,  5.2243e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.8617e-02,  3.7948e-02,  1.5430e-02,  ..., -4.6080e-02,\n",
       "                          2.5182e-02, -2.1738e-02],\n",
       "                        [-1.8435e-03, -5.1991e-02, -3.2392e-02,  ...,  3.7459e-02,\n",
       "                         -3.4919e-02, -5.8208e-03],\n",
       "                        [-2.8772e-02, -4.7383e-02, -2.0830e-03,  ..., -3.6180e-02,\n",
       "                         -6.5927e-03, -3.9275e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5639e-02,  3.7717e-02, -5.4524e-02,  ..., -2.2604e-02,\n",
       "                          2.4989e-02,  3.1692e-02],\n",
       "                        [ 3.1110e-02,  3.7357e-02, -5.2263e-02,  ..., -4.4658e-02,\n",
       "                          1.0120e-02, -4.7429e-02],\n",
       "                        [ 1.3397e-04, -1.5254e-02, -4.6793e-02,  ...,  5.0515e-03,\n",
       "                         -4.2390e-02,  5.8670e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6328e-03, -2.8925e-02,  3.0718e-02,  ...,  3.0650e-02,\n",
       "                         -9.6576e-03, -3.3106e-03],\n",
       "                        [-1.3018e-02,  4.4861e-03,  5.2488e-03,  ..., -5.2616e-02,\n",
       "                          3.1892e-02, -5.5361e-02],\n",
       "                        [-1.9712e-02,  1.2736e-02, -2.4515e-02,  ...,  2.0459e-02,\n",
       "                         -3.8740e-02, -3.5221e-02]]]])),\n",
       "             ('convs.1.bias',\n",
       "              tensor([-0.0191, -0.0192, -0.0325, -0.0164,  0.0282,  0.0112, -0.0189, -0.0005,\n",
       "                      -0.0475, -0.0438, -0.0249,  0.0289, -0.0309, -0.0563,  0.0539,  0.0182,\n",
       "                      -0.0266,  0.0254,  0.0414,  0.0389, -0.0157, -0.0285, -0.0178, -0.0272,\n",
       "                      -0.0154,  0.0569,  0.0223, -0.0314, -0.0285,  0.0016,  0.0400, -0.0041,\n",
       "                      -0.0221, -0.0338, -0.0242, -0.0429, -0.0405, -0.0399, -0.0368, -0.0382,\n",
       "                      -0.0185,  0.0477, -0.0411, -0.0261,  0.0123, -0.0317,  0.0293,  0.0340,\n",
       "                      -0.0071, -0.0353,  0.0433,  0.0520,  0.0388, -0.0288, -0.0313,  0.0278,\n",
       "                       0.0223,  0.0096, -0.0118,  0.0502, -0.0490, -0.0493,  0.0449,  0.0210,\n",
       "                       0.0491, -0.0570, -0.0343, -0.0187,  0.0477, -0.0411,  0.0018,  0.0308,\n",
       "                      -0.0258, -0.0532, -0.0381, -0.0131,  0.0070, -0.0335,  0.0442, -0.0504,\n",
       "                      -0.0541, -0.0148,  0.0523, -0.0450,  0.0496,  0.0566, -0.0365, -0.0436,\n",
       "                      -0.0181, -0.0536, -0.0329, -0.0431, -0.0133, -0.0263, -0.0380, -0.0255,\n",
       "                       0.0076,  0.0070, -0.0017,  0.0545])),\n",
       "             ('convs.2.weight',\n",
       "              tensor([[[[ 3.0234e-03,  2.8355e-02,  7.1525e-03,  ..., -4.6403e-02,\n",
       "                          4.9341e-02,  9.2535e-03],\n",
       "                        [-1.1152e-02,  9.1450e-03,  2.1298e-02,  ...,  4.1330e-02,\n",
       "                         -4.4465e-03,  3.5469e-02],\n",
       "                        [-2.1941e-02,  3.7049e-02, -2.2513e-02,  ..., -5.5284e-03,\n",
       "                          2.8441e-02,  4.5844e-02],\n",
       "                        [-1.9025e-05, -1.2400e-02,  2.5801e-03,  ...,  1.5880e-02,\n",
       "                          1.9740e-02, -4.6558e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0824e-02, -3.4612e-03, -3.5768e-02,  ..., -3.9841e-02,\n",
       "                         -1.5825e-02,  2.4840e-02],\n",
       "                        [-3.5375e-02,  4.1234e-02,  4.9618e-02,  ..., -1.8195e-02,\n",
       "                          3.8589e-02,  7.3825e-03],\n",
       "                        [ 3.8010e-02,  1.7481e-02,  2.8527e-02,  ...,  3.8553e-02,\n",
       "                         -1.8299e-02, -4.1000e-02],\n",
       "                        [ 1.3908e-02, -1.1960e-02,  2.9627e-03,  ...,  4.1355e-02,\n",
       "                         -2.2429e-02,  4.7926e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8273e-02,  1.5972e-02,  2.1347e-02,  ...,  1.4216e-02,\n",
       "                          3.7371e-02, -2.5851e-02],\n",
       "                        [ 1.0183e-02, -1.9263e-02,  1.1940e-02,  ..., -2.1998e-02,\n",
       "                         -1.0622e-02, -2.9530e-02],\n",
       "                        [ 1.3182e-02, -8.4058e-03,  9.2065e-03,  ..., -1.6232e-02,\n",
       "                          4.6007e-06,  3.0160e-02],\n",
       "                        [ 4.5627e-02, -1.4078e-02,  1.2988e-02,  ..., -4.4636e-02,\n",
       "                         -2.2448e-02,  3.2200e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.4682e-02, -4.3086e-02, -3.8156e-02,  ...,  3.3563e-02,\n",
       "                         -2.2819e-02, -4.0546e-02],\n",
       "                        [ 2.8956e-02,  3.8217e-02, -3.0888e-02,  ..., -1.9504e-02,\n",
       "                         -1.6613e-02,  1.3525e-02],\n",
       "                        [-3.4617e-02, -1.0644e-02,  1.9698e-02,  ...,  3.9971e-02,\n",
       "                          1.3777e-02,  1.2418e-02],\n",
       "                        [ 2.7802e-02, -4.1034e-02,  2.3164e-02,  ..., -4.5707e-03,\n",
       "                         -4.1454e-02, -2.2708e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7469e-02, -7.5986e-03, -4.4936e-02,  ..., -2.6687e-02,\n",
       "                          4.5190e-02,  7.7781e-03],\n",
       "                        [-3.0870e-02, -3.9802e-02, -1.1962e-02,  ..., -9.4939e-03,\n",
       "                          1.5525e-02, -4.2247e-02],\n",
       "                        [-3.3268e-02,  1.4600e-02, -2.6211e-02,  ...,  4.3382e-02,\n",
       "                          1.6539e-03,  1.5004e-02],\n",
       "                        [-3.0555e-02, -7.0349e-03, -4.4700e-02,  ..., -3.3040e-02,\n",
       "                          1.4532e-02, -2.6292e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3358e-03,  1.7915e-02, -4.1637e-02,  ...,  1.2780e-02,\n",
       "                          1.5449e-02, -6.1384e-03],\n",
       "                        [ 3.2721e-02,  2.9200e-02,  1.8779e-02,  ..., -3.5893e-02,\n",
       "                         -4.0244e-02,  4.6902e-02],\n",
       "                        [ 4.5556e-02, -7.4466e-03, -2.9403e-02,  ..., -4.4143e-02,\n",
       "                         -2.6378e-02, -2.2310e-02],\n",
       "                        [-3.8854e-03, -8.5424e-03, -3.4059e-02,  ..., -4.0731e-02,\n",
       "                         -1.1758e-02,  3.3232e-02]]]])),\n",
       "             ('convs.2.bias',\n",
       "              tensor([ 2.6860e-02,  4.6516e-02, -3.8794e-02,  2.2036e-02, -3.3163e-02,\n",
       "                       2.3711e-02,  2.2185e-02, -4.7217e-02, -4.7453e-03,  2.7784e-02,\n",
       "                      -9.2105e-03,  8.4840e-03, -4.4276e-02, -7.6510e-03,  2.9358e-02,\n",
       "                      -2.6262e-02, -2.5608e-02,  2.6232e-02, -3.6192e-02, -9.4658e-03,\n",
       "                      -1.3723e-02,  3.2341e-02, -3.3334e-03, -2.1146e-02, -3.0596e-02,\n",
       "                      -4.4647e-02,  3.4472e-02, -4.7945e-02,  3.0273e-02, -2.9285e-02,\n",
       "                       2.3517e-02, -3.7564e-02,  2.5421e-02,  2.6140e-02, -8.3359e-03,\n",
       "                       1.3539e-02, -1.9594e-02,  4.1882e-02, -7.4005e-03,  3.6360e-02,\n",
       "                       7.1459e-04,  1.5438e-02,  2.8231e-02, -1.1290e-02, -3.3403e-02,\n",
       "                       2.1239e-02, -4.4969e-02,  4.8645e-02, -4.9754e-02,  4.8561e-02,\n",
       "                       2.0098e-02, -2.4294e-03, -1.9299e-02,  4.3795e-02,  1.4081e-02,\n",
       "                       3.0224e-02, -2.4390e-02, -7.5545e-03,  3.5034e-03, -4.1884e-02,\n",
       "                      -1.0509e-02,  3.2949e-02,  5.2629e-03,  4.6223e-02,  4.9517e-02,\n",
       "                       1.2251e-02, -4.1231e-02,  3.5836e-02,  2.5529e-02,  4.8155e-02,\n",
       "                      -3.3541e-02, -3.3112e-02,  7.8309e-03,  5.6964e-03,  3.2171e-02,\n",
       "                      -2.7559e-02, -8.0645e-05,  9.9702e-03,  4.0640e-02,  3.3422e-02,\n",
       "                      -3.4050e-02,  4.3772e-02, -2.6931e-02,  4.0656e-02, -4.3255e-02,\n",
       "                       1.5189e-03, -3.3905e-02,  4.3717e-02, -5.7625e-03,  4.1643e-02,\n",
       "                       1.6090e-02, -3.0366e-02,  1.9264e-02, -2.8349e-04, -1.2117e-02,\n",
       "                      -9.9044e-03,  5.5634e-03,  3.9741e-02, -4.7834e-02, -3.0179e-02]))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_encoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, [Parameter containing:\n",
       "  tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-0.1352, -0.3804, -0.0035,  ..., -1.3826,  0.5351,  1.0329],\n",
       "          [ 0.9951, -0.3827,  2.6233,  ..., -1.0207,  1.9715,  0.1106],\n",
       "          ...,\n",
       "          [-0.5620,  0.3514, -0.4366,  ...,  1.6153, -0.0592,  0.2314],\n",
       "          [ 1.2819,  2.1936,  0.3616,  ...,  0.0555,  0.8765, -0.8002],\n",
       "          [-1.5785, -0.2578, -1.2632,  ...,  1.9032,  0.1489, -1.2119]],\n",
       "         requires_grad=True), Parameter containing:\n",
       "  tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-0.0446, -0.1373,  0.2730,  ...,  0.1510,  0.1139,  0.1337],\n",
       "          [ 0.2177,  1.9787,  0.2219,  ...,  0.3089, -0.5231, -1.7075],\n",
       "          ...,\n",
       "          [ 2.4204,  0.6877,  0.4054,  ...,  0.2642,  0.4043, -1.1890],\n",
       "          [-0.6415,  0.0572,  1.6200,  ...,  2.4325,  0.2091,  0.8547],\n",
       "          [ 0.3198,  0.9130, -1.3433,  ...,  0.5710, -1.0892,  0.0587]]), Parameter containing:\n",
       "  tensor([[[[ 0.0513, -0.0392, -0.0210,  ..., -0.0148, -0.0283, -0.0288],\n",
       "            [ 0.0320, -0.0690, -0.0075,  ...,  0.0536, -0.0545, -0.0411]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0271, -0.0569,  0.0283,  ..., -0.0410,  0.0319, -0.0027],\n",
       "            [ 0.0373, -0.0326,  0.0084,  ...,  0.0387, -0.0051,  0.0554]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0124, -0.0699,  0.0171,  ..., -0.0641,  0.0599,  0.0296],\n",
       "            [ 0.0321,  0.0313, -0.0232,  ..., -0.0673, -0.0102,  0.0256]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 0.0101,  0.0439,  0.0501,  ...,  0.0267, -0.0369, -0.0668],\n",
       "            [-0.0582, -0.0345, -0.0249,  ..., -0.0286, -0.0686,  0.0481]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0701, -0.0634, -0.0286,  ..., -0.0376, -0.0087,  0.0118],\n",
       "            [-0.0209,  0.0465,  0.0532,  ...,  0.0460,  0.0359,  0.0306]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0636,  0.0190, -0.0287,  ...,  0.0101, -0.0316, -0.0339],\n",
       "            [-0.0367,  0.0021, -0.0455,  ..., -0.0017, -0.0050,  0.0549]]]],\n",
       "         requires_grad=True), Parameter containing:\n",
       "  tensor([-0.0220,  0.0157, -0.0528, -0.0658, -0.0253, -0.0302, -0.0554,  0.0535,\n",
       "          -0.0167, -0.0699, -0.0170,  0.0005, -0.0069, -0.0150, -0.0142, -0.0128,\n",
       "          -0.0504, -0.0451,  0.0401,  0.0458,  0.0360,  0.0372,  0.0333, -0.0444,\n",
       "           0.0581,  0.0180, -0.0262,  0.0672,  0.0656,  0.0598,  0.0537,  0.0671,\n",
       "          -0.0386, -0.0345, -0.0604, -0.0573,  0.0027, -0.0684,  0.0484,  0.0066,\n",
       "           0.0063, -0.0359, -0.0670, -0.0464,  0.0205, -0.0137, -0.0226,  0.0253,\n",
       "          -0.0128,  0.0673, -0.0603,  0.0322,  0.0528, -0.0020, -0.0422,  0.0251,\n",
       "          -0.0010, -0.0396, -0.0462, -0.0656,  0.0198, -0.0130,  0.0674,  0.0019,\n",
       "           0.0490, -0.0422,  0.0033,  0.0063,  0.0032, -0.0076, -0.0352,  0.0099,\n",
       "           0.0354,  0.0700,  0.0634,  0.0642, -0.0262, -0.0540, -0.0013, -0.0283,\n",
       "          -0.0270, -0.0453, -0.0428, -0.0025, -0.0634, -0.0521,  0.0117, -0.0104,\n",
       "           0.0479, -0.0075, -0.0162,  0.0122,  0.0688, -0.0227,  0.0545,  0.0422,\n",
       "          -0.0506, -0.0301,  0.0257,  0.0363], requires_grad=True), Parameter containing:\n",
       "  tensor([[[[-5.6716e-02, -5.4520e-02,  4.7394e-02,  ...,  5.3057e-02,\n",
       "              2.3223e-03,  4.3600e-02],\n",
       "            [-5.1246e-02,  4.1496e-02,  4.1333e-02,  ...,  5.1012e-02,\n",
       "             -3.8865e-02, -4.2384e-02],\n",
       "            [-1.8132e-02, -4.6406e-02,  5.2645e-02,  ..., -1.3792e-03,\n",
       "             -2.8816e-02, -1.2643e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 1.7610e-02, -2.8728e-02,  3.0960e-02,  ...,  4.9913e-02,\n",
       "              2.2685e-02,  1.1208e-02],\n",
       "            [-2.1563e-02, -4.7843e-02, -1.8072e-02,  ...,  4.0477e-02,\n",
       "             -5.5858e-02, -5.3029e-02],\n",
       "            [-5.2622e-02, -4.4930e-02, -1.3372e-02,  ...,  4.0154e-02,\n",
       "              4.3273e-04,  4.8055e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 5.6628e-05, -4.5039e-02,  4.0294e-02,  ..., -4.1355e-02,\n",
       "              1.7308e-02,  5.4621e-03],\n",
       "            [-2.4061e-02, -1.5853e-02,  3.7839e-02,  ..., -4.3246e-02,\n",
       "              5.6183e-02, -2.5238e-02],\n",
       "            [ 5.7423e-02, -5.4671e-02,  3.5236e-02,  ...,  2.2812e-02,\n",
       "             -3.5250e-02,  5.2243e-02]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 4.8617e-02,  3.7948e-02,  1.5430e-02,  ..., -4.6080e-02,\n",
       "              2.5182e-02, -2.1738e-02],\n",
       "            [-1.8435e-03, -5.1991e-02, -3.2392e-02,  ...,  3.7459e-02,\n",
       "             -3.4919e-02, -5.8208e-03],\n",
       "            [-2.8772e-02, -4.7383e-02, -2.0830e-03,  ..., -3.6180e-02,\n",
       "             -6.5927e-03, -3.9275e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[ 2.5639e-02,  3.7717e-02, -5.4524e-02,  ..., -2.2604e-02,\n",
       "              2.4989e-02,  3.1692e-02],\n",
       "            [ 3.1110e-02,  3.7357e-02, -5.2263e-02,  ..., -4.4658e-02,\n",
       "              1.0120e-02, -4.7429e-02],\n",
       "            [ 1.3397e-04, -1.5254e-02, -4.6793e-02,  ...,  5.0515e-03,\n",
       "             -4.2390e-02,  5.8670e-03]]],\n",
       "  \n",
       "  \n",
       "          [[[-1.6328e-03, -2.8925e-02,  3.0718e-02,  ...,  3.0650e-02,\n",
       "             -9.6576e-03, -3.3106e-03],\n",
       "            [-1.3018e-02,  4.4861e-03,  5.2488e-03,  ..., -5.2616e-02,\n",
       "              3.1892e-02, -5.5361e-02],\n",
       "            [-1.9712e-02,  1.2736e-02, -2.4515e-02,  ...,  2.0459e-02,\n",
       "             -3.8740e-02, -3.5221e-02]]]], requires_grad=True), Parameter containing:\n",
       "  tensor([-0.0191, -0.0192, -0.0325, -0.0164,  0.0282,  0.0112, -0.0189, -0.0005,\n",
       "          -0.0475, -0.0438, -0.0249,  0.0289, -0.0309, -0.0563,  0.0539,  0.0182,\n",
       "          -0.0266,  0.0254,  0.0414,  0.0389, -0.0157, -0.0285, -0.0178, -0.0272,\n",
       "          -0.0154,  0.0569,  0.0223, -0.0314, -0.0285,  0.0016,  0.0400, -0.0041,\n",
       "          -0.0221, -0.0338, -0.0242, -0.0429, -0.0405, -0.0399, -0.0368, -0.0382,\n",
       "          -0.0185,  0.0477, -0.0411, -0.0261,  0.0123, -0.0317,  0.0293,  0.0340,\n",
       "          -0.0071, -0.0353,  0.0433,  0.0520,  0.0388, -0.0288, -0.0313,  0.0278,\n",
       "           0.0223,  0.0096, -0.0118,  0.0502, -0.0490, -0.0493,  0.0449,  0.0210,\n",
       "           0.0491, -0.0570, -0.0343, -0.0187,  0.0477, -0.0411,  0.0018,  0.0308,\n",
       "          -0.0258, -0.0532, -0.0381, -0.0131,  0.0070, -0.0335,  0.0442, -0.0504,\n",
       "          -0.0541, -0.0148,  0.0523, -0.0450,  0.0496,  0.0566, -0.0365, -0.0436,\n",
       "          -0.0181, -0.0536, -0.0329, -0.0431, -0.0133, -0.0263, -0.0380, -0.0255,\n",
       "           0.0076,  0.0070, -0.0017,  0.0545], requires_grad=True), Parameter containing:\n",
       "  tensor([[[[ 3.0234e-03,  2.8355e-02,  7.1525e-03,  ..., -4.6403e-02,\n",
       "              4.9341e-02,  9.2535e-03],\n",
       "            [-1.1152e-02,  9.1450e-03,  2.1298e-02,  ...,  4.1330e-02,\n",
       "             -4.4465e-03,  3.5469e-02],\n",
       "            [-2.1941e-02,  3.7049e-02, -2.2513e-02,  ..., -5.5284e-03,\n",
       "              2.8441e-02,  4.5844e-02],\n",
       "            [-1.9025e-05, -1.2400e-02,  2.5801e-03,  ...,  1.5880e-02,\n",
       "              1.9740e-02, -4.6558e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-4.0824e-02, -3.4612e-03, -3.5768e-02,  ..., -3.9841e-02,\n",
       "             -1.5825e-02,  2.4840e-02],\n",
       "            [-3.5375e-02,  4.1234e-02,  4.9618e-02,  ..., -1.8195e-02,\n",
       "              3.8589e-02,  7.3825e-03],\n",
       "            [ 3.8010e-02,  1.7481e-02,  2.8527e-02,  ...,  3.8553e-02,\n",
       "             -1.8299e-02, -4.1000e-02],\n",
       "            [ 1.3908e-02, -1.1960e-02,  2.9627e-03,  ...,  4.1355e-02,\n",
       "             -2.2429e-02,  4.7926e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-4.8273e-02,  1.5972e-02,  2.1347e-02,  ...,  1.4216e-02,\n",
       "              3.7371e-02, -2.5851e-02],\n",
       "            [ 1.0183e-02, -1.9263e-02,  1.1940e-02,  ..., -2.1998e-02,\n",
       "             -1.0622e-02, -2.9530e-02],\n",
       "            [ 1.3182e-02, -8.4058e-03,  9.2065e-03,  ..., -1.6232e-02,\n",
       "              4.6007e-06,  3.0160e-02],\n",
       "            [ 4.5627e-02, -1.4078e-02,  1.2988e-02,  ..., -4.4636e-02,\n",
       "             -2.2448e-02,  3.2200e-02]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[ 4.4682e-02, -4.3086e-02, -3.8156e-02,  ...,  3.3563e-02,\n",
       "             -2.2819e-02, -4.0546e-02],\n",
       "            [ 2.8956e-02,  3.8217e-02, -3.0888e-02,  ..., -1.9504e-02,\n",
       "             -1.6613e-02,  1.3525e-02],\n",
       "            [-3.4617e-02, -1.0644e-02,  1.9698e-02,  ...,  3.9971e-02,\n",
       "              1.3777e-02,  1.2418e-02],\n",
       "            [ 2.7802e-02, -4.1034e-02,  2.3164e-02,  ..., -4.5707e-03,\n",
       "             -4.1454e-02, -2.2708e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-4.7469e-02, -7.5986e-03, -4.4936e-02,  ..., -2.6687e-02,\n",
       "              4.5190e-02,  7.7781e-03],\n",
       "            [-3.0870e-02, -3.9802e-02, -1.1962e-02,  ..., -9.4939e-03,\n",
       "              1.5525e-02, -4.2247e-02],\n",
       "            [-3.3268e-02,  1.4600e-02, -2.6211e-02,  ...,  4.3382e-02,\n",
       "              1.6539e-03,  1.5004e-02],\n",
       "            [-3.0555e-02, -7.0349e-03, -4.4700e-02,  ..., -3.3040e-02,\n",
       "              1.4532e-02, -2.6292e-02]]],\n",
       "  \n",
       "  \n",
       "          [[[-9.3358e-03,  1.7915e-02, -4.1637e-02,  ...,  1.2780e-02,\n",
       "              1.5449e-02, -6.1384e-03],\n",
       "            [ 3.2721e-02,  2.9200e-02,  1.8779e-02,  ..., -3.5893e-02,\n",
       "             -4.0244e-02,  4.6902e-02],\n",
       "            [ 4.5556e-02, -7.4466e-03, -2.9403e-02,  ..., -4.4143e-02,\n",
       "             -2.6378e-02, -2.2310e-02],\n",
       "            [-3.8854e-03, -8.5424e-03, -3.4059e-02,  ..., -4.0731e-02,\n",
       "             -1.1758e-02,  3.3232e-02]]]], requires_grad=True), Parameter containing:\n",
       "  tensor([ 2.6860e-02,  4.6516e-02, -3.8794e-02,  2.2036e-02, -3.3163e-02,\n",
       "           2.3711e-02,  2.2185e-02, -4.7217e-02, -4.7453e-03,  2.7784e-02,\n",
       "          -9.2105e-03,  8.4840e-03, -4.4276e-02, -7.6510e-03,  2.9358e-02,\n",
       "          -2.6262e-02, -2.5608e-02,  2.6232e-02, -3.6192e-02, -9.4658e-03,\n",
       "          -1.3723e-02,  3.2341e-02, -3.3334e-03, -2.1146e-02, -3.0596e-02,\n",
       "          -4.4647e-02,  3.4472e-02, -4.7945e-02,  3.0273e-02, -2.9285e-02,\n",
       "           2.3517e-02, -3.7564e-02,  2.5421e-02,  2.6140e-02, -8.3359e-03,\n",
       "           1.3539e-02, -1.9594e-02,  4.1882e-02, -7.4005e-03,  3.6360e-02,\n",
       "           7.1459e-04,  1.5438e-02,  2.8231e-02, -1.1290e-02, -3.3403e-02,\n",
       "           2.1239e-02, -4.4969e-02,  4.8645e-02, -4.9754e-02,  4.8561e-02,\n",
       "           2.0098e-02, -2.4294e-03, -1.9299e-02,  4.3795e-02,  1.4081e-02,\n",
       "           3.0224e-02, -2.4390e-02, -7.5545e-03,  3.5034e-03, -4.1884e-02,\n",
       "          -1.0509e-02,  3.2949e-02,  5.2629e-03,  4.6223e-02,  4.9517e-02,\n",
       "           1.2251e-02, -4.1231e-02,  3.5836e-02,  2.5529e-02,  4.8155e-02,\n",
       "          -3.3541e-02, -3.3112e-02,  7.8309e-03,  5.6964e-03,  3.2171e-02,\n",
       "          -2.7559e-02, -8.0645e-05,  9.9702e-03,  4.0640e-02,  3.3422e-02,\n",
       "          -3.4050e-02,  4.3772e-02, -2.6931e-02,  4.0656e-02, -4.3255e-02,\n",
       "           1.5189e-03, -3.3905e-02,  4.3717e-02, -5.7625e-03,  4.1643e-02,\n",
       "           1.6090e-02, -3.0366e-02,  1.9264e-02, -2.8349e-04, -1.2117e-02,\n",
       "          -9.9044e-03,  5.5634e-03,  3.9741e-02, -4.7834e-02, -3.0179e-02],\n",
       "         requires_grad=True)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <generator object Module.parameters at 0x000001D415D19E08>\n",
    "len(list(word_encoder.parameters())), list(word_encoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1352, -0.3804, -0.0035,  ..., -1.3826,  0.5351,  1.0329],\n",
       "        [ 0.9951, -0.3827,  2.6233,  ..., -1.0207,  1.9715,  0.1106],\n",
       "        ...,\n",
       "        [-0.5620,  0.3514, -0.4366,  ...,  1.6153, -0.0592,  0.2314],\n",
       "        [ 1.2819,  2.1936,  0.3616,  ...,  0.0555,  0.8765, -0.8002],\n",
       "        [-1.5785, -0.2578, -1.2632,  ...,  1.9032,  0.1489, -1.2119]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(filter(lambda p: p.requires_grad, word_encoder.parameters()))\n",
    "print(len(a))\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word_encoder层的情况：**\n",
    "- Dropout 层没有参数\n",
    "- 除了extword_embed 层不需要训练外，其他的都需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "word_embed.weight\n",
      "torch.Size([5996, 100]) \t True\n",
      "\n",
      "extword_embed.weight\n",
      "torch.Size([5978, 100]) \t False\n",
      "\n",
      "convs.0.weight\n",
      "torch.Size([100, 1, 2, 100]) \t True\n",
      "\n",
      "convs.0.bias\n",
      "torch.Size([100]) \t True\n",
      "\n",
      "convs.1.weight\n",
      "torch.Size([100, 1, 3, 100]) \t True\n",
      "\n",
      "convs.1.bias\n",
      "torch.Size([100]) \t True\n",
      "\n",
      "convs.2.weight\n",
      "torch.Size([100, 1, 4, 100]) \t True\n",
      "\n",
      "convs.2.bias\n",
      "torch.Size([100]) \t True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(list(word_encoder.parameters())))\n",
    "for parameter_name, parameter in zip(word_encoder.state_dict().keys(), word_encoder.parameters()):\n",
    "    print(parameter_name)\n",
    "    print(parameter.size(), '\\t', parameter.requires_grad)\n",
    "    # 比 \\n 的空行短\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sent层的参数情况：**\n",
    "- 两个隐藏层10和11，都需要训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "sent_lstm.weight_ih_l0\n",
      "torch.Size([1024, 300]) \t True\n",
      "\n",
      "sent_lstm.weight_hh_l0\n",
      "torch.Size([1024, 256]) \t True\n",
      "\n",
      "sent_lstm.bias_ih_l0\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.bias_hh_l0\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.weight_ih_l0_reverse\n",
      "torch.Size([1024, 300]) \t True\n",
      "\n",
      "sent_lstm.weight_hh_l0_reverse\n",
      "torch.Size([1024, 256]) \t True\n",
      "\n",
      "sent_lstm.bias_ih_l0_reverse\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.bias_hh_l0_reverse\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.weight_ih_l1\n",
      "torch.Size([1024, 512]) \t True\n",
      "\n",
      "sent_lstm.weight_hh_l1\n",
      "torch.Size([1024, 256]) \t True\n",
      "\n",
      "sent_lstm.bias_ih_l1\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.bias_hh_l1\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.weight_ih_l1_reverse\n",
      "torch.Size([1024, 512]) \t True\n",
      "\n",
      "sent_lstm.weight_hh_l1_reverse\n",
      "torch.Size([1024, 256]) \t True\n",
      "\n",
      "sent_lstm.bias_ih_l1_reverse\n",
      "torch.Size([1024]) \t True\n",
      "\n",
      "sent_lstm.bias_hh_l1_reverse\n",
      "torch.Size([1024]) \t True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_rep_size = 300\n",
    "sent = SentEncoder(sent_rep_size)\n",
    "# TypeError: object of type 'generator' has no len()\n",
    "print(len(list(sent.parameters())))\n",
    "for parameter_name, parameter in zip(sent.state_dict().keys(), sent.parameters()):\n",
    "    print(parameter_name)\n",
    "    print(parameter.size(), '\\t', parameter.requires_grad)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention层的参数情况：**\n",
    "- 都需要训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "weight\n",
      "torch.Size([512, 512]) \t True\n",
      "\n",
      "bias\n",
      "torch.Size([512]) \t True\n",
      "\n",
      "query\n",
      "torch.Size([512]) \t True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 256 * 2\n",
    "doc_rep_size = sent_hidden_size * 2\n",
    "attention = Attention(doc_rep_size)\n",
    "print(len(list(attention.parameters())))\n",
    "for parameter_name, parameter in zip(attention.state_dict().keys(), attention.parameters()):\n",
    "    print(parameter_name)\n",
    "    print(parameter.size(), '\\t', parameter.requires_grad)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[262144, 512, 512]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.prod(list(parameter.size())) for parameter in attention.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # # 输入的特征维度 300=100*3，3个卷积后的特征拼接\n",
    "        self.sent_rep_size = 300\n",
    "        # hidden_size 为 Attention 层的隐藏单元数，为sent层中lstm层的隐藏单元数的两倍\n",
    "        self.doc_rep_size = sent_hidden_size * 2\n",
    "        \n",
    "        self.all_parameters = {}\n",
    "        \n",
    "        # 把 requires_grad 的层的参数都存到这里\n",
    "        parameters = [] \n",
    "        # 2 2\n",
    "        # print(len(set(vocab._id2extword)), len(vocab._id2extword))\n",
    "        self.word_encoder = WordCNNEncoder(vocab)       \n",
    "        parameters.extend(list(filter(lambda p: p.requires_grad, self.word_encoder.parameters())))\n",
    "        self.sent_encoder = SentEncoder(self.sent_rep_size)        \n",
    "        parameters.extend(list(filter(lambda p: p.requires_grad, self.sent_encoder.parameters())))        \n",
    "        self.sent_attention = Attention(self.doc_rep_size)\n",
    "        parameters.extend(list(filter(lambda p: p.requires_grad, self.sent_attention.parameters())))\n",
    "        # 输出层使用全连接层，14 分类\n",
    "        self.out = nn.Linear(self.doc_rep_size, vocab.label_size, bias=True)\n",
    "        parameters.extend(list(filter(lambda p: p.requires_grad, self.out.parameters())))\n",
    "\n",
    "        if use_cuda:\n",
    "            self.to(device)\n",
    "        \n",
    "        # 全部待训练的参数\n",
    "        if len(parameters) > 0:\n",
    "            self.all_parameters[\"basic_parameters\"] = parameters\n",
    "\n",
    "        logging.info('Build model with cnn word encoder, lstm sent encoder.')\n",
    "    \n",
    "        # 这里的 self 是 model 实例，直接调用未定义的方法？？？？？？？？？？？？？？？\n",
    "        para_num = sum([np.prod(list(p.size())) for p in self.parameters()])\n",
    "        print([np.prod(list(p.size())) for p in self.parameters()])\n",
    "        \n",
    "        # 从多少个字节 b，转换到多少 Mb\n",
    "        logging.info('Model param num: %.2f M.' % (para_num / 1e6))\n",
    "        logging.info('Model param num: %.2f M.' % (para_num / 1024 / 1024))\n",
    "\n",
    "    def forward(self, batch_inputs):\n",
    "        \"\"\"doc_len = word_dims？？？？？？？\"\"\"\n",
    "        # batch_inputs 包含三个 shape 一样的变量（batch_inputs1, batch_inputs2, batch_masks）\n",
    "        \n",
    "        # batch_inputs(batch_inputs1, batch_inputs2): b x doc_len x sent_len\n",
    "        # batch_masks : b x doc_len x sent_len\n",
    "        \n",
    "        batch_inputs1, batch_inputs2, batch_masks = batch_inputs\n",
    "        \n",
    "        # b = batch_size, doc_len = max_doc_len, sent_len = max_sent_len\n",
    "        # 同 batch_inputs2, batch_masks， batch_inputs1.shape = (b，doc_len，sent_len)  \n",
    "        batch_size, max_doc_len, max_sent_len = batch_inputs1.shape[0], batch_inputs1.shape[1], batch_inputs1.shape[2]\n",
    "        \n",
    "        # reshape：sent_num = batch_size * max_doc_len\n",
    "        batch_inputs1 = batch_inputs1.view(batch_size * max_doc_len, max_sent_len)  # （sen_num，sent_len）\n",
    "        batch_inputs2 = batch_inputs2.view(batch_size * max_doc_len, max_sent_len)  # （sen_num，sent_len）\n",
    "        batch_masks = batch_masks.view(batch_size * max_doc_len, max_sent_len)  # （sen_num，sent_len）\n",
    "        \n",
    "        # word_encoder层传入参数，函数式编程\n",
    "        sent_reps = self.word_encoder(batch_inputs1, batch_inputs2)  # （sen_num，sent_rep_size=100*3）\n",
    "\n",
    "        sent_reps = sent_reps.view(batch_size, max_doc_len, self.sent_rep_size)  # b x doc_len x sent_rep_size\n",
    "        batch_masks = batch_masks.view(batch_size, max_doc_len, max_sent_len)  # b x doc_len x max_sent_len\n",
    "        sent_masks = batch_masks.bool().any(2).float()  # b x doc_len\n",
    "\n",
    "        sent_hiddens = self.sent_encoder(sent_reps, sent_masks)  # b x doc_len x doc_rep_size\n",
    "        doc_reps, atten_scores = self.sent_attention(sent_hiddens, sent_masks)  # b x doc_rep_size\n",
    "\n",
    "        batch_outputs = self.out(doc_reps)  # b x num_labels\n",
    "\n",
    "        return batch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试，类 Vocab，函数 word_size 运行了\n",
      "测试，类 Vocab，函数 load_pretrained_embs 运行了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-29 10:45:49,424 INFO: Load extword embed: words 5978, dims 100.\n",
      "2020-07-29 10:45:49,474 INFO: Build model with cnn word encoder, lstm sent encoder.\n",
      "2020-07-29 10:45:49,476 INFO: Model param num: 4.28 M.\n",
      "2020-07-29 10:45:49,476 INFO: Model param num: 4.08 M.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5978 5978\n",
      "测试，类 Vocab，函数 label_size 运行了\n",
      "[599600, 597800, 20000, 100, 30000, 100, 40000, 100, 307200, 262144, 1024, 1024, 307200, 262144, 1024, 1024, 524288, 262144, 1024, 1024, 524288, 262144, 1024, 1024, 262144, 512, 512, 7168, 14]\n"
     ]
    }
   ],
   "source": [
    "# self就是总的模型， self.parameters() 的个数 = 29 = 8 + 16 + 3 + 2\n",
    "model = Model(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_encoder每运行一次，都会增加，导致结果不一致 assert len(set(self._id2extword)) == len(self._id2extword)\n",
    "\n",
    "需要重新运行一次vocab才行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
